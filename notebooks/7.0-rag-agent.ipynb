{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb81d93",
   "metadata": {},
   "source": [
    "# Building an Analytics Dashboard Assistant with OpenAI\n",
    "\n",
    "This tutorial will guide you through creating an intelligent analytics assistant using OpenAI's Assistants API. Our assistant will be capable of:\n",
    "- Analyzing multiple data files using File Search\n",
    "- Generating visualizations and insights using Code Interpreter\n",
    "- Creating interactive dashboards based on user queries\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai pandas matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e269e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51b7dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef20d54",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI Client\n",
    "\n",
    "First, we'll set up our OpenAI client with the appropriate API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3403b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8334a78",
   "metadata": {},
   "source": [
    "## Creating the Analytics Assistant\n",
    "\n",
    "We'll create an assistant that combines both Code Interpreter and File Search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9dd720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analytics_assistant():\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Analytics Dashboard Assistant\",\n",
    "        instructions=\"\"\"You are an expert data analyst and visualization specialist. \n",
    "        Your role is to:\n",
    "        1. Analyze data files provided by users\n",
    "        2. Generate insightful visualizations\n",
    "        3. Create comprehensive analytics dashboards\n",
    "        4. Explain trends and patterns in the data\n",
    "        Always provide clear explanations of your analysis process.\"\"\",\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[\n",
    "            {\"type\": \"code_interpreter\"},\n",
    "            {\"type\": \"file_search\"}\n",
    "        ]\n",
    "    )\n",
    "    return assistant\n",
    "\n",
    "analytics_assistant = create_analytics_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c1f58",
   "metadata": {},
   "source": [
    "## Setting Up the Vector Store for File Search\n",
    "\n",
    "The File Search capability requires setting up a vector store for our data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "394bb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(name=\"Analytics Files\"):\n",
    "    vector_store = client.beta.vector_stores.create(\n",
    "        name=name,\n",
    "    )\n",
    "    return vector_store\n",
    "\n",
    "def add_files_to_vector_store(vector_store_id, file_ids):\n",
    "    batch = client.beta.vector_stores.file_batches.create_and_poll(\n",
    "        vector_store_id=vector_store_id,\n",
    "        file_ids=file_ids\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "# Create vector store\n",
    "vector_store = create_vector_store()\n",
    "\n",
    "# Update assistant with vector store\n",
    "analytics_assistant = client.beta.assistants.update(\n",
    "    assistant_id=analytics_assistant.id,\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a074f",
   "metadata": {},
   "source": [
    "## File Upload Helper Functions\n",
    "\n",
    "Let's create helper functions to handle file uploads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0557f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_path):\n",
    "    \"\"\"Upload a file for the assistant to use\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        response = client.files.create(\n",
    "            file=file,\n",
    "            purpose='assistants'\n",
    "        )\n",
    "    return response\n",
    "\n",
    "def attach_files_to_assistant(assistant_id, file_ids):\n",
    "    \"\"\"Attach files to the assistant for code interpreter\"\"\"\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        tool_resources={\n",
    "            \"code_interpreter\": {\n",
    "                \"file_ids\": file_ids\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6239c",
   "metadata": {},
   "source": [
    "## Creating and Managing Threads\n",
    "\n",
    "Now let's create functions to manage conversation threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9181c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_with_files(files=None):\n",
    "    \"\"\"Create a new thread with optional files\"\"\"\n",
    "    if files:\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I've uploaded some files for analysis.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}]\n",
    "                } for file_id in files\n",
    "            ]\n",
    "        }]\n",
    "        thread = client.beta.threads.create(messages=messages)\n",
    "    else:\n",
    "        thread = client.beta.threads.create()\n",
    "    return thread\n",
    "\n",
    "def add_message_to_thread(thread_id, content, files=None):\n",
    "    \"\"\"Add a message to an existing thread\"\"\"\n",
    "    if files:\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=content,\n",
    "            attachments=[\n",
    "                {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}]\n",
    "                } for file_id in files\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=content\n",
    "        )\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180595c1",
   "metadata": {},
   "source": [
    "## Running the Assistant and Handling Responses\n",
    "\n",
    "Here's how we'll handle running the assistant and processing its responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f54276df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(thread_id, assistant_id):\n",
    "    \"\"\"Create and manage a run of the assistant\"\"\"\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        \n",
    "        if run.status == 'completed':\n",
    "            break\n",
    "        elif run.status == 'failed':\n",
    "            raise Exception(f\"Run failed: {run.last_error}\")\n",
    "        elif run.status == 'requires_action':\n",
    "            # Handle any required actions (function calls, etc.)\n",
    "            pass\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Get messages after run completes\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    return messages\n",
    "\n",
    "def display_assistant_response(messages):\n",
    "    \"\"\"Display the assistant's response including any generated visualizations\"\"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"assistant\":\n",
    "            for content in message.content:\n",
    "                if content.type == 'text':\n",
    "                    print(content.text.value)\n",
    "                elif content.type == 'image_file':\n",
    "                    # Handle image display\n",
    "                    file_id = content.image_file.file_id\n",
    "                    image_data = client.files.content(file_id)\n",
    "                    # Display image using IPython\n",
    "                    display(HTML(f'<img src=\"data:image/png;base64,{image_data}\" />'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87804e12",
   "metadata": {},
   "source": [
    "## Example Usage: Creating an Analytics Dashboard\n",
    "\n",
    "Let's put it all together with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d03ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload sample data files\n",
    "pdf_data_new = upload_file('./pdfs/ai-agents-paper.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05685979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-Etp2hzyR6gz36m95CEqNsJ'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "134fcb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFileBatch(id='vsfb_515333e3b1c847a59103815ebd0b1145', created_at=1736790901, file_counts=FileCounts(cancelled=0, completed=2, failed=0, in_progress=0, total=2), object='vector_store.file_batch', status='completed', vector_store_id='vs_x44ONrYHPHr1QSAs0DYZmMFL')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = add_files_to_vector_store(vector_store.id, [pdf_data.id,pdf_data_new.id])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d08231",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=analytics_assistant.id,\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2194d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Add files to vector store\n",
    "# # add_files_to_vector_store(vector_store.id, [sales_data.id])\n",
    "\n",
    "# # Create a thread with the files\n",
    "thread = create_thread_with_files([pdf_data.id, pdf_data_new.id])\n",
    "\n",
    "# Ask for analysis and dashboard creation\n",
    "analysis_request = \"\"\"\n",
    "Summarize the pdfs into a simple bullet point structure.\n",
    "\"\"\"\n",
    "\n",
    "add_message_to_thread(thread.id, analysis_request)\n",
    "\n",
    "# Run the assistant\n",
    "messages = run_assistant(thread.id, assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63b741fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a concise bullet point summary of the PDF files you uploaded:\n",
       "\n",
       "- **Memory Reflection in Agents**:\n",
       "  - Emulates human cognitive ability to summarize and infer complex information.\n",
       "  - Generative Agent framework generates key questions from memories to derive insights.\n",
       "  - Insights are hierarchical, using existing insights for higher abstraction【13:0†source】.\n",
       "\n",
       "- **Planning Module for Complex Tasks**:\n",
       "  - Inspired by human capacity to deconstruct tasks into subtasks.\n",
       "  - Agents aim to behave reasonably by receiving feedback during planning【13:0†source】.\n",
       "\n",
       "- **Memory Operations**:\n",
       "  - Important operations include memory reading, writing, and reflection.\n",
       "  - Information extraction uses recency, relevance, and importance criteria【13:4†source】.\n",
       "\n",
       "- **Agent Construction and Application**:\n",
       "  - Surveys on LLM-based autonomous agents focus on construction, application, and evaluation.\n",
       "  - Issues discussed include architecture design and capability acquisition【13:9†source】.\n",
       "\n",
       "- **Profiling Module for Agents**:\n",
       "  - Defines agent roles and is crucial in therapeutic and learning environments.\n",
       "  - Methods like handcrafting are used to specify agent characteristics【13:19†source】.\n",
       "\n",
       "- **Memory Formats and Structures**:\n",
       "  - Memory stored in natural language, embeddings, and databases for varied applications.\n",
       "  - Structures include lists and hierarchical trees capturing goals and plans【13:14†source】.\n",
       "\n",
       "This summary captures the core concepts discussed across both documents related to the memory, planning, and architectural designs of large language model-based autonomous agents."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c35d3",
   "metadata": {},
   "source": [
    "# GH What happens if a new PDF is added to that vector file store? Is there an auto-poll functionality to see a new file was updated and auto-rerun the summarization to refelect the new or updated paper/file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload sample data files\n",
    "pdf_data = upload_file('./pdfs/paper.pdf')\n",
    "\n",
    "# # Add files to vector store\n",
    "# add_files_to_vector_store(vector_store.id, [sales_data.id])\n",
    "\n",
    "# Create a thread with the files\n",
    "thread = create_thread_with_files([pdf_data.id])\n",
    "\n",
    "# Ask for analysis and dashboard creation\n",
    "analysis_request = \"\"\"\n",
    "Summarize the pdf data.\n",
    "\"\"\"\n",
    "\n",
    "add_message_to_thread(thread.id, analysis_request)\n",
    "\n",
    "# Run the assistant\n",
    "messages = run_assistant(thread.id, analytics_assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c44d5e9",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "1. **File Management**:\n",
    "   - Keep track of file IDs and clean up unused files\n",
    "   - Use appropriate file formats (CSV, JSON, Excel) for data\n",
    "   - Consider file size limits (512MB per file)\n",
    "\n",
    "2. **Vector Store Organization**:\n",
    "   - Group related files in the same vector store\n",
    "   - Use descriptive names for vector stores\n",
    "   - Monitor vector store expiration policies\n",
    "\n",
    "3. **Error Handling**:\n",
    "   - Implement proper error handling for API calls\n",
    "   - Monitor run status and handle failures gracefully\n",
    "   - Validate file uploads and data formats\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - Use appropriate chunk sizes for File Search\n",
    "   - Monitor token usage and context windows\n",
    "   - Implement request rate limiting\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated how to create an intelligent analytics assistant that combines the power of OpenAI's Code Interpreter and File Search capabilities. The assistant can analyze multiple data sources, generate visualizations, and create interactive dashboards based on user queries.\n",
    "\n",
    "You can extend this foundation by:\n",
    "- Adding more sophisticated visualization capabilities\n",
    "- Implementing custom dashboard templates\n",
    "- Adding support for more data formats\n",
    "- Creating specialized analysis functions\n",
    "- Implementing caching for frequently accessed data\n",
    "\n",
    "Remember to handle API keys securely and implement proper error handling in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-assistants",
   "language": "python",
   "name": "gpt-assistants"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
