{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb81d93",
   "metadata": {},
   "source": [
    "# Building an Analytics Dashboard Assistant with OpenAI\n",
    "\n",
    "This tutorial will guide you through creating an intelligent analytics assistant using OpenAI's Assistants API. Our assistant will be capable of:\n",
    "- Analyzing multiple data files using File Search\n",
    "- Generating visualizations and insights using Code Interpreter\n",
    "- Creating interactive dashboards based on user queries\n",
    "\n",
    "## Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai pandas matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e269e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b7dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef20d54",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI Client\n",
    "\n",
    "First, we'll set up our OpenAI client with the appropriate API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3403b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8334a78",
   "metadata": {},
   "source": [
    "## Creating the Analytics Assistant\n",
    "\n",
    "We'll create an assistant that combines both Code Interpreter and File Search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9dd720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analytics_assistant():\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"Analytics Dashboard Assistant\",\n",
    "        instructions=\"\"\"You are an expert data analyst and visualization specialist. \n",
    "        Your role is to:\n",
    "        1. Analyze data files provided by users\n",
    "        2. Generate insightful visualizations\n",
    "        3. Create comprehensive analytics dashboards\n",
    "        4. Explain trends and patterns in the data\n",
    "        Always provide clear explanations of your analysis process.\"\"\",\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[\n",
    "            {\"type\": \"code_interpreter\"},\n",
    "            {\"type\": \"file_search\"}\n",
    "        ]\n",
    "    )\n",
    "    return assistant\n",
    "\n",
    "analytics_assistant = create_analytics_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c1f58",
   "metadata": {},
   "source": [
    "## Setting Up the Vector Store for File Search\n",
    "\n",
    "The File Search capability requires setting up a vector store for our data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394bb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(name=\"Analytics Files\"):\n",
    "    vector_store = client.beta.vector_stores.create(\n",
    "        name=name,\n",
    "    )\n",
    "    return vector_store\n",
    "\n",
    "def add_files_to_vector_store(vector_store_id, file_ids):\n",
    "    batch = client.beta.vector_stores.file_batches.create_and_poll(\n",
    "        vector_store_id=vector_store_id,\n",
    "        file_ids=file_ids\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "# Create vector store\n",
    "vector_store = create_vector_store()\n",
    "\n",
    "# Update assistant with vector store\n",
    "analytics_assistant = client.beta.assistants.update(\n",
    "    assistant_id=analytics_assistant.id,\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a074f",
   "metadata": {},
   "source": [
    "## File Upload Helper Functions\n",
    "\n",
    "Let's create helper functions to handle file uploads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0557f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_path):\n",
    "    \"\"\"Upload a file for the assistant to use\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        response = client.files.create(\n",
    "            file=file,\n",
    "            purpose='assistants'\n",
    "        )\n",
    "    return response\n",
    "\n",
    "def attach_files_to_assistant(assistant_id, file_ids):\n",
    "    \"\"\"Attach files to the assistant for code interpreter\"\"\"\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant_id,\n",
    "        tool_resources={\n",
    "            \"code_interpreter\": {\n",
    "                \"file_ids\": file_ids\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6239c",
   "metadata": {},
   "source": [
    "## Creating and Managing Threads\n",
    "\n",
    "Now let's create functions to manage conversation threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9181c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_with_files(files=None):\n",
    "    \"\"\"Create a new thread with optional files\"\"\"\n",
    "    if files:\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I've uploaded some files for analysis.\",\n",
    "            \"attachments\": [\n",
    "                {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}]\n",
    "                } for file_id in files\n",
    "            ]\n",
    "        }]\n",
    "        thread = client.beta.threads.create(messages=messages)\n",
    "    else:\n",
    "        thread = client.beta.threads.create()\n",
    "    return thread\n",
    "\n",
    "def add_message_to_thread(thread_id, content, files=None):\n",
    "    \"\"\"Add a message to an existing thread\"\"\"\n",
    "    if files:\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=content,\n",
    "            attachments=[\n",
    "                {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"tools\": [{\"type\": \"code_interpreter\"}, {\"type\": \"file_search\"}]\n",
    "                } for file_id in files\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=content\n",
    "        )\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180595c1",
   "metadata": {},
   "source": [
    "## Running the Assistant and Handling Responses\n",
    "\n",
    "Here's how we'll handle running the assistant and processing its responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54276df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(thread_id, assistant_id):\n",
    "    \"\"\"Create and manage a run of the assistant\"\"\"\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        \n",
    "        if run.status == 'completed':\n",
    "            break\n",
    "        elif run.status == 'failed':\n",
    "            raise Exception(f\"Run failed: {run.last_error}\")\n",
    "        elif run.status == 'requires_action':\n",
    "            # Handle any required actions (function calls, etc.)\n",
    "            pass\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Get messages after run completes\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    return messages\n",
    "\n",
    "def display_assistant_response(messages):\n",
    "    \"\"\"Display the assistant's response including any generated visualizations\"\"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"assistant\":\n",
    "            for content in message.content:\n",
    "                if content.type == 'text':\n",
    "                    print(content.text.value)\n",
    "                elif content.type == 'image_file':\n",
    "                    # Handle image display\n",
    "                    file_id = content.image_file.file_id\n",
    "                    image_data = client.files.content(file_id)\n",
    "                    # Display image using IPython\n",
    "                    display(HTML(f'<img src=\"data:image/png;base64,{image_data}\" />'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87804e12",
   "metadata": {},
   "source": [
    "## Example Usage: Creating an Analytics Dashboard\n",
    "\n",
    "Let's put it all together with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d03ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload sample data files\n",
    "pdf_data_new = upload_file('./pdfs/ai-agents-paper.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05685979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-6btRe3kHaTTDvBfww662MG'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data_new.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134fcb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFileBatch(id='vsfb_52ce69881fee483a81424da0395be857', created_at=1752510062, file_counts=FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1), object='vector_store.file_batch', status='completed', vector_store_id='vs_68752e4145308191868f1e23c0ab2b63')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = add_files_to_vector_store(vector_store.id, [pdf_data_new.id,pdf_data_new.id])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d08231",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=analytics_assistant.id,\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2194d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Add files to vector store\n",
    "# # add_files_to_vector_store(vector_store.id, [sales_data.id])\n",
    "\n",
    "# # Create a thread with the files\n",
    "thread = create_thread_with_files([pdf_data_new.id, pdf_data_new.id])\n",
    "\n",
    "# Ask for analysis and dashboard creation\n",
    "analysis_request = \"\"\"\n",
    "Summarize the pdfs into a simple bullet point structure.\n",
    "\"\"\"\n",
    "\n",
    "add_message_to_thread(thread.id, analysis_request)\n",
    "\n",
    "# Run the assistant\n",
    "messages = run_assistant(thread.id, assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b741fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a bullet-point summary of the content from the PDF titled \"ai-agents-paper.pdf\":\n",
       "\n",
       "- **Purpose and Scope:**\n",
       "  - Discusses the construction and applications of LLM-based autonomous agents in social sciences, natural sciences, and engineering.\n",
       "  - Provides strategies for evaluating LLM-based autonomous agents using subjective and objective criteria【11:0†source】.\n",
       "\n",
       "- **LLM-based Autonomous Agent Construction:**\n",
       "  - Two main aspects: Architecture design to leverage LLM capabilities and agent capability acquisition for task-specific functionality.\n",
       "  - Architecture setup akin to network structure; capability acquisition similar to network parameter learning【11:0†source】.\n",
       "  - Unified framework for agent architecture design and capability acquisition strategies【11:18†source】.\n",
       "\n",
       "- **Agent Architecture Design:**\n",
       "  - Focus on creating architectures that enhance LLM functionality through integration with additional modules.\n",
       "  - Emphasis on bridging capabilities of traditional LLMs with requirements of autonomous agents【11:0†source】.\n",
       "\n",
       "- **Capability Acquisition Strategies:**\n",
       "  - Fine-tuning with task-specific datasets as a direct method.\n",
       "  - Alternative strategies that do not require fine-tuning are suitable for both open and closed-source LLMs, albeit with context window limitations【11:10†source】【11:12†source】.\n",
       "\n",
       "- **Applications in Various Fields:**\n",
       "  - **Social Science:** Simulation experiments, mental health support, political science, economy, and social simulations.\n",
       "  - **Natural Science:** Experiment assistants and education tools.\n",
       "  - **Engineering:** Civil, computer, and aerospace engineering applications【11:10†source】.\n",
       "\n",
       "- **Memory and Reflection in Agents:**\n",
       "  - Importance of managing memory (e.g., dealing with overflow and duplicates).\n",
       "  - Agents can reflect on past experiences to derive insights and improve decision-making【11:4†source】【11:8†source】.\n",
       "\n",
       "- **Planning Module:**\n",
       "  - Decomposition of tasks into subtasks for efficient problem-solving.\n",
       "  - Use of single-path and multi-path reasoning with feedback mechanisms【11:9†source】【11:16†source】.\n",
       "\n",
       "- **Evaluation and Challenges:**\n",
       "  - Subjective evaluations like human annotations and Turing tests.\n",
       "  - Objective evaluations with specific metrics and benchmarks【11:10†source】.\n",
       "  - Challenges include improving inference speed and optimizing agent actions using LLMs【11:14†source】【11:15†source】."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "943f101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload sample data files\n",
    "pdf_data = upload_file('./pdfs/paper.pdf')\n",
    "\n",
    "# # Add files to vector store\n",
    "# add_files_to_vector_store(vector_store.id, [sales_data.id])\n",
    "\n",
    "# Create a thread with the files\n",
    "thread = create_thread_with_files([pdf_data.id])\n",
    "\n",
    "# Ask for analysis and dashboard creation\n",
    "analysis_request = \"\"\"\n",
    "Summarize the pdf data.\n",
    "\"\"\"\n",
    "\n",
    "add_message_to_thread(thread.id, analysis_request)\n",
    "\n",
    "# Run the assistant\n",
    "messages = run_assistant(thread.id, analytics_assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1ae0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The uploaded PDF file, titled \"paper.pdf,\" provides an in-depth exploration of the Transformer model, particularly in the context of machine translation and English constituency parsing.\n",
       "\n",
       "1. **Transformer Model Overview**:\n",
       "   - The document discusses the Transformer, a sequence transduction model which relies entirely on attention mechanisms, specifically self-attention, rather than recurrent layers used in typical encoder-decoder architectures【9:7†source】.\n",
       "\n",
       "2. **Model Variations and Performance**:\n",
       "   - The file presents various configurations of the Transformer model, evaluating their performance on English-to-German translations. Different model sizes, attention head variations, and embedding settings are analyzed for their impact on BLEU scores and training efficiency【9:2†source】【9:5†source】.\n",
       "   - It highlights the more efficient performance of the Transformer (big model) over previous state-of-the-art models in translation tasks【9:5†source】.\n",
       "\n",
       "3. **Machine Translation**:\n",
       "   - The paper reports that the Transformer model achieves high BLEU scores with relatively lower training costs compared to other architectures, marking a significant improvement in translation tasks【9:5†source】【9:7†source】.\n",
       "\n",
       "4. **English Constituency Parsing**:\n",
       "   - The document also delves into the application of the Transformer model for English constituency parsing, where it outperforms other models, confirming its versatility beyond just translation tasks【9:12†source】.\n",
       "\n",
       "5. **Technical Details**:\n",
       "   - Detailed descriptions of model components, such as multi-head attention and position-wise feed-forward networks, are included【9:10†source】【9:15†source】.\n",
       "   - Discussions on positional encoding and regularization techniques such as dropout and label smoothing are also part of the study【9:3†source】【9:5†source】.\n",
       "\n",
       "This summary captures the primary focus and findings presented in the PDF, showcasing both the theoretical insights and practical evaluations that the document provides on the Transformer model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c44d5e9",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "1. **File Management**:\n",
    "   - Keep track of file IDs and clean up unused files\n",
    "   - Use appropriate file formats (CSV, JSON, Excel) for data\n",
    "   - Consider file size limits (512MB per file)\n",
    "\n",
    "2. **Vector Store Organization**:\n",
    "   - Group related files in the same vector store\n",
    "   - Use descriptive names for vector stores\n",
    "   - Monitor vector store expiration policies\n",
    "\n",
    "3. **Error Handling**:\n",
    "   - Implement proper error handling for API calls\n",
    "   - Monitor run status and handle failures gracefully\n",
    "   - Validate file uploads and data formats\n",
    "\n",
    "4. **Performance Optimization**:\n",
    "   - Use appropriate chunk sizes for File Search\n",
    "   - Monitor token usage and context windows\n",
    "   - Implement request rate limiting\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated how to create an intelligent analytics assistant that combines the power of OpenAI's Code Interpreter and File Search capabilities. The assistant can analyze multiple data sources, generate visualizations, and create interactive dashboards based on user queries.\n",
    "\n",
    "You can extend this foundation by:\n",
    "- Adding more sophisticated visualization capabilities\n",
    "- Implementing custom dashboard templates\n",
    "- Adding support for more data formats\n",
    "- Creating specialized analysis functions\n",
    "- Implementing caching for frequently accessed data\n",
    "\n",
    "Remember to handle API keys securely and implement proper error handling in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-assistants",
   "language": "python",
   "name": "gpt-assistants"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
