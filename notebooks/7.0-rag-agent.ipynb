{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb81d93",
   "metadata": {},
   "source": [
    "# Building an Intelligent RAG Agent with OpenAI's Responses API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we'll build a powerful Retrieval-Augmented Generation (RAG) agent using OpenAI's **Responses API**. Unlike traditional RAG implementations that require managing separate embedding services and vector databases, OpenAI's Responses API provides a fully-managed solution that handles:\n",
    "\n",
    "- **Document Processing**: Automatic parsing, chunking, and embedding\n",
    "- **Vector Storage**: Managed vector stores with semantic search\n",
    "- **Data Analysis**: Built-in code interpreter for analytics and visualizations\n",
    "- **Seamless Integration**: Combine document retrieval with computational capabilities\n",
    "\n",
    "### What You'll Build\n",
    "\n",
    "By the end of this tutorial, you'll have created an intelligent analytics agent capable of:\n",
    "- Analyzing multiple documents using file search (RAG)\n",
    "- Processing data files with code interpreter\n",
    "- Generating visualizations and insights\n",
    "- Creating comprehensive analytics reports\n",
    "- Answering questions based on your document corpus\n",
    "\n",
    "### Why Responses API?\n",
    "\n",
    "The Responses API (replacing the deprecated Assistants API) offers:\n",
    "- **Simpler architecture**: No threads or assistants to manage\n",
    "- **Stateless design**: Instructions per request, not stored server-side\n",
    "- **Conversation continuity**: Simple `previous_response_id` chaining\n",
    "- **Unified interface**: One API for both RAG and code execution\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5788a",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q openai pandas matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e269e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"OpenAI client initialized successfully!\")\n",
    "print(\"Ready to build your RAG agent with the Responses API!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8334a78",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setting Up Your Knowledge Base\n",
    "\n",
    "### Understanding Vector Stores\n",
    "\n",
    "Vector stores are the foundation of the RAG (Retrieval-Augmented Generation) approach. They:\n",
    "- Store document embeddings for semantic search\n",
    "- Enable efficient retrieval of relevant information\n",
    "- Support up to 10,000 files per store\n",
    "- Handle various file formats automatically\n",
    "\n",
    "Let's create a vector store for our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_base(name=\"Analytics Knowledge Base\", expiration_days=30):\n",
    "    \"\"\"\n",
    "    Create a vector store for storing and retrieving documents.\n",
    "    \n",
    "    Args:\n",
    "        name: Descriptive name for the vector store\n",
    "        expiration_days: Days of inactivity before auto-deletion (cost management)\n",
    "    \n",
    "    Returns:\n",
    "        Vector store object with id and metadata\n",
    "    \"\"\"\n",
    "    vector_store = client.vector_stores.create(\n",
    "        name=name,\n",
    "        expires_after={\n",
    "            \"anchor\": \"last_active_at\",\n",
    "            \"days\": expiration_days\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Created vector store: {name}\")\n",
    "    print(f\"  ID: {vector_store.id}\")\n",
    "    print(f\"  Auto-expires after {expiration_days} days of inactivity\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "# Create our knowledge base\n",
    "knowledge_base = create_knowledge_base(\"Research Papers & Reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a074f",
   "metadata": {},
   "source": [
    "### Uploading Documents to Your Knowledge Base\n",
    "\n",
    "Now let's create helper functions to upload and manage documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_document_to_knowledge_base(file_path, vector_store_id):\n",
    "    \"\"\"\n",
    "    Upload a document and add it to the knowledge base (vector store).\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the document file\n",
    "        vector_store_id: ID of the target vector store\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with file_id and status\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    try:\n",
    "        # Upload file to OpenAI\n",
    "        print(f\"Uploading {file_name}...\")\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_response = client.files.create(\n",
    "                file=file,\n",
    "                purpose='assistants'\n",
    "            )\n",
    "        \n",
    "        # Add to vector store\n",
    "        print(f\"Adding to knowledge base...\")\n",
    "        client.vector_stores.files.create(\n",
    "            vector_store_id=vector_store_id,\n",
    "            file_id=file_response.id\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Successfully added {file_name} to knowledge base\")\n",
    "        return {\"file_id\": file_response.id, \"file_name\": file_name, \"status\": \"success\"}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error uploading {file_name}: {str(e)}\")\n",
    "        return {\"file_name\": file_name, \"status\": \"failed\", \"error\": str(e)}\n",
    "\n",
    "def upload_multiple_documents(file_paths, vector_store_id):\n",
    "    \"\"\"\n",
    "    Upload multiple documents to the knowledge base.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of file paths to upload\n",
    "        vector_store_id: ID of the target vector store\n",
    "    \n",
    "    Returns:\n",
    "        List of upload results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for file_path in file_paths:\n",
    "        result = upload_document_to_knowledge_base(file_path, vector_store_id)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Wait for processing\n",
    "    print(\"\\nWaiting for document processing...\")\n",
    "    time.sleep(3)\n",
    "    print(\"✓ Documents ready for search!\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload_example",
   "metadata": {},
   "source": [
    "### Example: Upload Sample Documents\n",
    "\n",
    "Let's upload some sample documents to our knowledge base. For this example, we'll use documents from your pdfs folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample_upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Upload documents from your pdfs folder\n",
    "# Modify these paths to match your actual documents\n",
    "\n",
    "sample_documents = [\n",
    "    './pdfs/arxiv_paper_1.pdf',  # Replace with your actual file paths\n",
    "    # Add more documents as needed\n",
    "]\n",
    "\n",
    "# Upload documents (uncomment when you have actual files)\n",
    "# uploaded_files = upload_multiple_documents(sample_documents, knowledge_base.id)\n",
    "\n",
    "# For demonstration, let's show the structure\n",
    "print(\"Example upload structure:\")\n",
    "print(\"uploaded_files = upload_multiple_documents(['file1.pdf', 'file2.pdf'], knowledge_base.id)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building the RAG Agent with Responses API\n",
    "\n",
    "### Understanding the Responses API Approach\n",
    "\n",
    "Unlike the old Assistants API, the Responses API is much simpler:\n",
    "\n",
    "**Old Way (Assistants API):**\n",
    "```python\n",
    "1. Create assistant\n",
    "2. Create thread\n",
    "3. Add message to thread\n",
    "4. Create run\n",
    "5. Poll for completion\n",
    "6. Retrieve messages\n",
    "```\n",
    "\n",
    "**New Way (Responses API):**\n",
    "```python\n",
    "response = client.responses.create(\n",
    "    input=\"Your question\",\n",
    "    tools=[{\"type\": \"file_search\", \"vector_store_ids\": [vs_id]}]\n",
    ")\n",
    "```\n",
    "\n",
    "Let's create our RAG agent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rag_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGAgent:\n",
    "    \"\"\"\n",
    "    A RAG (Retrieval-Augmented Generation) agent using OpenAI's Responses API.\n",
    "    \n",
    "    This agent can:\n",
    "    - Search through documents in a vector store\n",
    "    - Perform data analysis with code interpreter\n",
    "    - Maintain conversation context\n",
    "    - Generate comprehensive reports\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store_id, model=\"gpt-4o\"):\n",
    "        self.vector_store_id = vector_store_id\n",
    "        self.model = model\n",
    "        self.conversation_history = []\n",
    "        self.last_response_id = None\n",
    "        \n",
    "    def query(self, question, use_code_interpreter=False, instructions=None):\n",
    "        \"\"\"\n",
    "        Query the knowledge base and get an AI-generated response.\n",
    "        \n",
    "        Args:\n",
    "            question: The user's question\n",
    "            use_code_interpreter: Whether to enable code interpreter for analysis\n",
    "            instructions: Custom instructions for this query (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Response object from OpenAI\n",
    "        \"\"\"\n",
    "        # Default instructions for RAG agent\n",
    "        if instructions is None:\n",
    "            instructions = \"\"\"You are an expert research analyst and data scientist.\n",
    "            Use the file_search tool to find relevant information from the knowledge base.\n",
    "            Provide accurate, well-sourced answers based on the documents.\n",
    "            If you're unsure or the information isn't in the documents, say so clearly.\n",
    "            Always cite your sources when possible.\"\"\"\n",
    "        \n",
    "        # Build tools list\n",
    "        tools = [{\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [self.vector_store_id],\n",
    "            \"max_num_results\": 5\n",
    "        }]\n",
    "        \n",
    "        if use_code_interpreter:\n",
    "            tools.append({\n",
    "                \"type\": \"code_interpreter\",\n",
    "                \"container\": {\"type\": \"auto\"}\n",
    "            })\n",
    "        \n",
    "        # Create response request\n",
    "        request_params = {\n",
    "            \"input\": question,\n",
    "            \"model\": self.model,\n",
    "            \"instructions\": instructions,\n",
    "            \"tools\": tools\n",
    "        }\n",
    "        \n",
    "        # Add previous response ID if continuing conversation\n",
    "        if self.last_response_id:\n",
    "            request_params[\"previous_response_id\"] = self.last_response_id\n",
    "        \n",
    "        # Make the API call\n",
    "        response = client.responses.create(**request_params)\n",
    "        \n",
    "        # Update conversation state\n",
    "        self.last_response_id = response.id\n",
    "        self.conversation_history.append({\n",
    "            \"question\": question,\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def display_response(self, response):\n",
    "        \"\"\"\n",
    "        Display the response in a formatted way.\n",
    "        \n",
    "        Args:\n",
    "            response: Response object from OpenAI\n",
    "        \"\"\"\n",
    "        for item in response.output:\n",
    "            if hasattr(item, 'content'):\n",
    "                for content in item.content:\n",
    "                    if hasattr(content, 'text'):\n",
    "                        display(Markdown(content.text))\n",
    "                    elif hasattr(content, 'image_file'):\n",
    "                        # Handle generated images\n",
    "                        file_id = content.image_file.file_id\n",
    "                        print(f\"Generated visualization (file_id: {file_id})\")\n",
    "    \n",
    "    def extract_citations(self, response):\n",
    "        \"\"\"\n",
    "        Extract source citations from the response.\n",
    "        \n",
    "        Args:\n",
    "            response: Response object from OpenAI\n",
    "        \n",
    "        Returns:\n",
    "            Set of cited filenames\n",
    "        \"\"\"\n",
    "        citations = set()\n",
    "        \n",
    "        for item in response.output:\n",
    "            if hasattr(item, 'content'):\n",
    "                for content in item.content:\n",
    "                    if hasattr(content, 'annotations'):\n",
    "                        for annotation in content.annotations:\n",
    "                            if hasattr(annotation, 'filename'):\n",
    "                                citations.add(annotation.filename)\n",
    "        \n",
    "        return citations\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"\n",
    "        Reset the conversation history and start fresh.\n",
    "        \"\"\"\n",
    "        self.last_response_id = None\n",
    "        self.conversation_history = []\n",
    "        print(\"Conversation reset. Starting fresh!\")\n",
    "\n",
    "print(\"RAGAgent class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example_usage",
   "metadata": {},
   "source": [
    "### Example: Using the RAG Agent\n",
    "\n",
    "Now let's create an instance of our RAG agent and use it to query our knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG agent\n",
    "rag_agent = RAGAgent(vector_store_id=knowledge_base.id)\n",
    "\n",
    "print(\"RAG Agent created and ready!\")\n",
    "print(f\"Connected to knowledge base: {knowledge_base.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query 1: Simple question\n",
    "question1 = \"What are the main topics covered in the documents? Provide a summary.\"\n",
    "\n",
    "print(f\"Question: {question1}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "response1 = rag_agent.query(question1)\n",
    "rag_agent.display_response(response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Show citations\n",
    "citations = rag_agent.extract_citations(response1)\n",
    "if citations:\n",
    "    print(\"\\nSources cited:\")\n",
    "    for citation in citations:\n",
    "        print(f\"  - {citation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "followup_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query 2: Follow-up question (uses conversation context)\n",
    "question2 = \"Can you provide more details about the first topic you mentioned?\"\n",
    "\n",
    "print(f\"Follow-up Question: {question2}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "response2 = rag_agent.query(question2)\n",
    "rag_agent.display_response(response2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_analytics",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Advanced Analytics with Code Interpreter\n",
    "\n",
    "### Combining RAG with Data Analysis\n",
    "\n",
    "One of the most powerful features is combining document retrieval with computational analysis. Let's see how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analytics_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract data from documents and visualize\n",
    "analytics_query = \"\"\"Based on the documents in the knowledge base, \n",
    "extract any numerical data, statistics, or metrics mentioned. \n",
    "Then create visualizations to illustrate the key findings.\n",
    "Provide a comprehensive analysis with charts and insights.\"\"\"\n",
    "\n",
    "print(f\"Analytics Query:\\n{analytics_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Enable code interpreter for this query\n",
    "response = rag_agent.query(\n",
    "    analytics_query,\n",
    "    use_code_interpreter=True,\n",
    "    instructions=\"\"\"You are an expert data analyst and research scientist.\n",
    "    Use file_search to find relevant data in the documents.\n",
    "    Use code_interpreter to process, analyze, and visualize the data.\n",
    "    Create clear, informative visualizations.\n",
    "    Explain your analysis methodology and findings.\"\"\"\n",
    ")\n",
    "\n",
    "rag_agent.display_response(response)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_file_analysis",
   "metadata": {},
   "source": [
    "### Working with Data Files\n",
    "\n",
    "You can also upload data files (CSV, Excel, JSON) directly for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_sample_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset for demonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2024-01-01', periods=90, freq='D')\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'revenue': np.random.randint(50000, 150000, 90) + np.arange(90) * 500,\n",
    "    'costs': np.random.randint(20000, 80000, 90) + np.arange(90) * 200,\n",
    "    'customers': np.random.randint(500, 2000, 90) + np.arange(90) * 10,\n",
    "    'conversion_rate': np.random.uniform(0.02, 0.08, 90)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "data_file_path = 'business_metrics.csv'\n",
    "sample_data.to_csv(data_file_path, index=False)\n",
    "\n",
    "print(\"Sample business metrics dataset created!\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(sample_data.head())\n",
    "print(f\"\\nDataset shape: {sample_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_data_file",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_file(file_path, query, model=\"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    Upload and analyze a data file using the Responses API.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the data file\n",
    "        query: Analysis request\n",
    "        model: OpenAI model to use\n",
    "    \n",
    "    Returns:\n",
    "        Response object from OpenAI\n",
    "    \"\"\"\n",
    "    # Upload the file\n",
    "    print(f\"Uploading {os.path.basename(file_path)}...\")\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_response = client.files.create(\n",
    "            file=file,\n",
    "            purpose='assistants'\n",
    "        )\n",
    "    \n",
    "    print(f\"File uploaded: {file_response.id}\")\n",
    "    \n",
    "    # Create input with file attachment\n",
    "    input_data = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_file\",\n",
    "                    \"file_id\": file_response.id\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": query\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    instructions = \"\"\"You are an expert business analyst and data scientist.\n",
    "    Analyze the provided data file thoroughly.\n",
    "    Create insightful visualizations.\n",
    "    Identify trends, patterns, and anomalies.\n",
    "    Provide actionable recommendations based on the data.\"\"\"\n",
    "    \n",
    "    # Make the request\n",
    "    response = client.responses.create(\n",
    "        input=input_data,\n",
    "        model=model,\n",
    "        instructions=instructions,\n",
    "        tools=[{\n",
    "            \"type\": \"code_interpreter\",\n",
    "            \"container\": {\"type\": \"auto\"}\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return response, file_response.id\n",
    "\n",
    "# Analyze the sample data\n",
    "analysis_request = \"\"\"Please analyze this business metrics data:\n",
    "1. Calculate key statistics and trends\n",
    "2. Create visualizations for revenue, costs, and profit over time\n",
    "3. Analyze customer growth and conversion rate trends\n",
    "4. Identify any interesting patterns or anomalies\n",
    "5. Provide strategic recommendations based on the data\"\"\"\n",
    "\n",
    "print(f\"\\nAnalyzing data file...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "data_response, file_id = analyze_data_file(data_file_path, analysis_request)\n",
    "\n",
    "# Display results\n",
    "for item in data_response.output:\n",
    "    if hasattr(item, 'content'):\n",
    "        for content in item.content:\n",
    "            if hasattr(content, 'text'):\n",
    "                display(Markdown(content.text))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_advanced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Building a Complete Analytics Dashboard\n",
    "\n",
    "Let's combine everything we've learned to create a comprehensive analytics workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dashboard_class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyticsDashboard:\n",
    "    \"\"\"\n",
    "    A comprehensive analytics dashboard combining RAG and data analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store_id, model=\"gpt-4o\"):\n",
    "        self.rag_agent = RAGAgent(vector_store_id, model)\n",
    "        self.model = model\n",
    "        self.reports = []\n",
    "    \n",
    "    def generate_executive_summary(self):\n",
    "        \"\"\"\n",
    "        Generate an executive summary from the knowledge base.\n",
    "        \"\"\"\n",
    "        query = \"\"\"Generate an executive summary of the key findings and insights \n",
    "        from all documents in the knowledge base. Include:\n",
    "        1. Main topics and themes\n",
    "        2. Critical findings\n",
    "        3. Key metrics and data points\n",
    "        4. Strategic implications\"\"\"\n",
    "        \n",
    "        print(\"Generating Executive Summary...\\n\")\n",
    "        response = self.rag_agent.query(query, use_code_interpreter=True)\n",
    "        \n",
    "        self.reports.append({\n",
    "            \"type\": \"executive_summary\",\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def analyze_trends(self):\n",
    "        \"\"\"\n",
    "        Analyze trends from the documents.\n",
    "        \"\"\"\n",
    "        query = \"\"\"Identify and analyze key trends mentioned in the documents.\n",
    "        Extract any time-series data or historical comparisons.\n",
    "        Create visualizations showing trend progression.\n",
    "        Provide insights on trend directions and implications.\"\"\"\n",
    "        \n",
    "        print(\"Analyzing Trends...\\n\")\n",
    "        response = self.rag_agent.query(query, use_code_interpreter=True)\n",
    "        \n",
    "        self.reports.append({\n",
    "            \"type\": \"trend_analysis\",\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def compare_documents(self):\n",
    "        \"\"\"\n",
    "        Compare and contrast documents in the knowledge base.\n",
    "        \"\"\"\n",
    "        query = \"\"\"Compare and contrast the different documents in the knowledge base.\n",
    "        Identify:\n",
    "        1. Common themes and differences\n",
    "        2. Contradictions or agreements\n",
    "        3. Complementary information\n",
    "        4. Gaps in coverage\n",
    "        Create a comparison table or chart if appropriate.\"\"\"\n",
    "        \n",
    "        print(\"Comparing Documents...\\n\")\n",
    "        response = self.rag_agent.query(query, use_code_interpreter=True)\n",
    "        \n",
    "        self.reports.append({\n",
    "            \"type\": \"document_comparison\",\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def generate_recommendations(self):\n",
    "        \"\"\"\n",
    "        Generate actionable recommendations based on all insights.\n",
    "        \"\"\"\n",
    "        query = \"\"\"Based on all the information in our knowledge base and our conversation,\n",
    "        generate actionable recommendations. Include:\n",
    "        1. Strategic priorities\n",
    "        2. Tactical next steps\n",
    "        3. Risk considerations\n",
    "        4. Success metrics\n",
    "        Organize recommendations by priority and feasibility.\"\"\"\n",
    "        \n",
    "        print(\"Generating Recommendations...\\n\")\n",
    "        response = self.rag_agent.query(query, use_code_interpreter=False)\n",
    "        \n",
    "        self.reports.append({\n",
    "            \"type\": \"recommendations\",\n",
    "            \"response_id\": response.id\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_report_summary(self):\n",
    "        \"\"\"\n",
    "        Get a summary of all generated reports.\n",
    "        \"\"\"\n",
    "        print(\"Generated Reports:\")\n",
    "        for i, report in enumerate(self.reports, 1):\n",
    "            print(f\"{i}. {report['type'].replace('_', ' ').title()} (ID: {report['response_id']})\")\n",
    "\n",
    "print(\"AnalyticsDashboard class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "use_dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the analytics dashboard\n",
    "dashboard = AnalyticsDashboard(vector_store_id=knowledge_base.id)\n",
    "\n",
    "print(\"Analytics Dashboard initialized!\")\n",
    "print(\"\\nAvailable methods:\")\n",
    "print(\"  - generate_executive_summary()\")\n",
    "print(\"  - analyze_trends()\")\n",
    "print(\"  - compare_documents()\")\n",
    "print(\"  - generate_recommendations()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate executive summary\n",
    "# Uncomment when you have documents in your knowledge base\n",
    "\n",
    "# summary_response = dashboard.generate_executive_summary()\n",
    "# dashboard.rag_agent.display_response(summary_response)\n",
    "\n",
    "print(\"Example usage:\")\n",
    "print(\"summary = dashboard.generate_executive_summary()\")\n",
    "print(\"dashboard.rag_agent.display_response(summary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Best Practices and Production Considerations\n",
    "\n",
    "### Cost Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cost_management",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_stats(vector_store_id):\n",
    "    \"\"\"\n",
    "    Get statistics about a vector store.\n",
    "    \"\"\"\n",
    "    vs = client.vector_stores.retrieve(vector_store_id)\n",
    "    \n",
    "    print(f\"Vector Store: {vs.name}\")\n",
    "    print(f\"ID: {vs.id}\")\n",
    "    print(f\"Files: {vs.file_counts.completed} completed\")\n",
    "    print(f\"Status: {vs.status}\")\n",
    "    print(f\"\\nCost Considerations:\")\n",
    "    print(f\"  - File Search: $2.50 per 1,000 queries\")\n",
    "    print(f\"  - Storage: $0.10/GB/day (first GB free)\")\n",
    "    print(f\"  - Code Interpreter: $0.03 per session\")\n",
    "    \n",
    "    if vs.expires_after:\n",
    "        print(f\"\\nAuto-deletion: After {vs.expires_after.days} days of inactivity\")\n",
    "\n",
    "# Example usage\n",
    "get_vector_store_stats(knowledge_base.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_handling",
   "metadata": {},
   "source": [
    "### Error Handling and Retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust_query",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def robust_query(rag_agent, question, max_retries=3, use_code_interpreter=False):\n",
    "    \"\"\"\n",
    "    Query with automatic retry logic.\n",
    "    \n",
    "    Args:\n",
    "        rag_agent: RAGAgent instance\n",
    "        question: Query string\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        use_code_interpreter: Whether to use code interpreter\n",
    "    \n",
    "    Returns:\n",
    "        Response object or None if all retries fail\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = rag_agent.query(question, use_code_interpreter=use_code_interpreter)\n",
    "            return response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = (attempt + 1) * 2\n",
    "                print(f\"Retrying in {wait_time} seconds...\")\n",
    "                sleep(wait_time)\n",
    "            else:\n",
    "                print(\"Max retries reached. Query failed.\")\n",
    "                return None\n",
    "\n",
    "print(\"Robust query function defined.\")\n",
    "print(\"Usage: response = robust_query(rag_agent, 'Your question here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "### Cleanup and Resource Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_resources(vector_store_ids=None, file_ids=None):\n",
    "    \"\"\"\n",
    "    Clean up vector stores and files to manage costs.\n",
    "    \n",
    "    Args:\n",
    "        vector_store_ids: List of vector store IDs to delete\n",
    "        file_ids: List of file IDs to delete\n",
    "    \"\"\"\n",
    "    if vector_store_ids:\n",
    "        print(\"Deleting vector stores...\")\n",
    "        for vs_id in vector_store_ids:\n",
    "            try:\n",
    "                client.vector_stores.delete(vs_id)\n",
    "                print(f\"  ✓ Deleted vector store: {vs_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error deleting {vs_id}: {e}\")\n",
    "    \n",
    "    if file_ids:\n",
    "        print(\"\\nDeleting files...\")\n",
    "        for file_id in file_ids:\n",
    "            try:\n",
    "                client.files.delete(file_id)\n",
    "                print(f\"  ✓ Deleted file: {file_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error deleting {file_id}: {e}\")\n",
    "    \n",
    "    print(\"\\nCleanup complete!\")\n",
    "\n",
    "# Example cleanup (uncomment when needed)\n",
    "# cleanup_resources(vector_store_ids=[knowledge_base.id])\n",
    "\n",
    "print(\"Cleanup function ready.\")\n",
    "print(\"Use with caution - this will permanently delete resources!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations! You've learned how to build a sophisticated RAG (Retrieval-Augmented Generation) agent using OpenAI's Responses API.\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "1. **Knowledge Base Setup**\n",
    "   - Creating and managing vector stores\n",
    "   - Uploading and organizing documents\n",
    "   - Cost-effective expiration policies\n",
    "\n",
    "2. **RAG Agent Development**\n",
    "   - Building a reusable RAGAgent class\n",
    "   - Querying documents with file_search\n",
    "   - Maintaining conversation context\n",
    "   - Extracting citations and sources\n",
    "\n",
    "3. **Advanced Analytics**\n",
    "   - Combining file_search with code_interpreter\n",
    "   - Analyzing data files\n",
    "   - Generating visualizations\n",
    "   - Creating comprehensive reports\n",
    "\n",
    "4. **Production Best Practices**\n",
    "   - Error handling and retries\n",
    "   - Cost management\n",
    "   - Resource cleanup\n",
    "   - Dashboard patterns\n",
    "\n",
    "### Key Advantages of Responses API\n",
    "\n",
    "Compared to the deprecated Assistants API:\n",
    "- **Simpler**: No threads, assistants, or complex polling\n",
    "- **More efficient**: Direct responses without polling loops\n",
    "- **Flexible**: Stateless design with easy conversation chaining\n",
    "- **Powerful**: Same tools (file_search, code_interpreter) with better UX\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Upload your own documents and build a custom knowledge base\n",
    "- Experiment with different query patterns and instructions\n",
    "- Build specialized agents for your domain\n",
    "- Integrate with your applications and workflows\n",
    "- Explore streaming responses for real-time updates\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [OpenAI Responses API Documentation](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [File Search Guide](https://platform.openai.com/docs/guides/tools-file-search)\n",
    "- [Code Interpreter Guide](https://platform.openai.com/docs/guides/tools-code-interpreter)\n",
    "- [OpenAI Cookbook](https://cookbook.openai.com/)\n",
    "\n",
    "### Final Tips\n",
    "\n",
    "1. **Start small**: Begin with a few documents and expand gradually\n",
    "2. **Iterate on instructions**: Experiment with different prompts for better results\n",
    "3. **Monitor costs**: Set expiration policies and clean up unused resources\n",
    "4. **Handle errors**: Implement robust error handling for production use\n",
    "5. **Cite sources**: Always encourage citation of source documents\n",
    "\n",
    "Happy building! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
