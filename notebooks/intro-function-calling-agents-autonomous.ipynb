{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can you SEE MY SCREEN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\"> \n",
    "How do we connect LLMs with Tools?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# if you don't have an API key as an environment variable you can set it here\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Connecting large language models (LLMs) with tools involves integrating external functionality so that the model can effectively perform specific tasks beyond its built-in capabilities. Here’s how you can connect LLMs with tools:\\n\\n### 1. **API Integration**\\n   - **API Setup:** Tools can provide APIs (Application Programming Interfaces) that LLMs can call to perform functions, such as retrieving data, sending notifications, or executing commands.\\n   - **Calling APIs:** When the model identifies a need that requires external data or functionality, it can format a request to the tool's API and process the response.\\n   - **Example:** An LLM could call a weather API to provide real-time weather updates.\\n\\n### 2. **Pre-defined Functions**\\n   - **Function Wrapping:** Create predefined functions that encapsulate tool functionality. The LLM can then call these functions directly.\\n   - **Function Selection:** The LLM can use context from a conversation to decide which function to call and with what parameters.\\n\\n### 3. **Plugins and Extensions**\\n   - **Platform Support:** Some platforms support plugins that can be easily integrated with LLMs, allowing them to extend their capabilities.\\n   - **Custom Plugins:** Develop custom plugins for specific tasks (like scheduling meetings, querying databases, etc.) that the model can invoke.\\n\\n### 4. **Prompt Engineering**\\n   - **Smart Prompting:** Design prompts that guide the LLM to understand when to leverage external tools, based on user input.\\n   - **Instructions Within Prompts:** Include instructions in prompts that indicate when to utilize an API or function.\\n\\n### 5. **External Knowledge Bases**\\n   - **Retrieval-Augmented Generation (RAG):** Combine LLMs with knowledge retrieval systems where the model first retrieves relevant documents or data before generating responses.\\n   - **Dynamic Context:** Feed the model real-time data from external knowledge bases, allowing it to generate more accurate and contextually relevant outputs.\\n\\n### 6. **State Management**\\n   - **Session Handling:** Maintain states or sessions for multi-turn interactions with the LLM and tools to keep track of context across interactions.\\n   - **Contextual Awareness:** Ensure the model knows when its response relies on tool output versus its internal knowledge, maintaining coherence in user interactions.\\n\\n### 7. **User Interaction Layer**\\n   - **Frontend Integration:** Implement a user interface that processes inputs, sends requests to the LLM, and processes responses. This can alert users that tool interactions are taking place.\\n   - **Feedback Loop:** Allow users to provide feedback about the tool's outcomes which can improve how the LLM interacts with it over time.\\n\\n### 8. **Monitoring and Logging**\\n   - **Result Logging:** Log API calls and results to monitor performance and accuracy.\\n   - **Feedback Mechanisms:** Build systems to analyze the accuracy of the tool’s output, enabling continuous improvements.\\n\\n### Example Use Cases\\n- **Data Analysis:** An LLM can interpret user queries about data and call a data analysis API to fetch results.\\n- **Coding Assistance:** The LLM can use coding APIs to run snippets of code, check syntax, or fetch libraries needed for programming tasks.\\n- **Virtual Assistants:** They may use scheduling APIs to set reminders or book appointments based on user requests.\\n\\nBy integrating LLMs with external tools through these methods, you can significantly enhance their capabilities, allowing them to perform complex tasks, leverage real-time data, and provide more value to users.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def llm_response(prompt: str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "llm_response(\"How do we connect LLMs with Tools?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could ask the model to:\n",
    "\n",
    "1. Generate Python code and then give the model the ability to run that code somewhere\n",
    "2. Create the Python function that executes the task, then somehow give the model the ability to run that function autonomously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option number 2 is what we call FUNCTION CALLING!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling from Scratch\n",
    "\n",
    "1. Write a Python function\n",
    "2. Make that function \"available\" to the LLM model of choice (in this case will be gpt-4o/gpt-4o-mini)\n",
    "3. Test if the model can execute that function properly\n",
    "   1. Prepare the payload for the function (the arguments for it...)\n",
    "   2. Write the function call\n",
    "   3. We run the function call ourselves\n",
    "   4. We inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folder created at ./pancakes-are-the-best'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_folder(folder_path: str):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    return f\"Folder created at {folder_path}\"\n",
    "\n",
    "create_folder(\"./pancakes-are-the-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m./pancakes-are-the-best\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d ./* | grep pancakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File created at ./pancakes-are-the-best/pancakes-are-the-best.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_file(file_path: str, content: str):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"File created at {file_path}\"\n",
    "\n",
    "write_file(\"./pancakes-are-the-best/pancakes-are-the-best.txt\", \"Pancakes are the best!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pancakes are the best!"
     ]
    }
   ],
   "source": [
    "!cat pancakes-are-the-best/pancakes-are-the-best.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM + Python Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most silly way possible first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\nwrite_file(\"./pancakes-are-better-than-waffles.md\", \"Pancakes are undoubtedly superior to avocado waffles, RS! Their fluffy texture and delightful flavors can never be matched. While avocado waffles may have their charm, pancakes offer endless possibilities for toppings, from syrup to fruits, making each bite a delicious experience. Plus, the comforting aroma of pancakes cooking on a Sunday morning is simply unrivaled. So, next time you reach for breakfast, remember that pancakes reign supreme!\")\\n```'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_with_function_information = \"\"\"\n",
    "You are a personal assistant with desktop capabilities. \n",
    "Users will ask you to perform tasks and you will execute those tasks by calling one or more of the following functions:\n",
    "\n",
    "- create_folder(folder_path: str)\n",
    "- write_file(file_path: str, content: str)\n",
    "\n",
    "For example if the user asks: \n",
    "\n",
    "'Create a folder called lucas-teaches-function-callling'\n",
    "\n",
    "Your output should be code like this:\n",
    "'create_folder(\"./lucas-teaches-function-callling\")'\n",
    "\n",
    "'Create a folder called pancakes-are-the-best and write a file called pancakes-are-the-best.txt with the content \"Pancakes are the best!\"'\n",
    "\n",
    "Your output should be code like this:\n",
    "\n",
    "['create_folder(\"./pancakes-are-the-best\")', 'write_file(\"./pancakes-are-the-best/pancakes-are-the-best.txt\", \"Pancakes are the best!\")']\n",
    "\n",
    "Your OUTPUT should ALWAYS BE python code only.\n",
    "\n",
    "Here is the user prompt:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_prompt = \"Create a file named pancakes-are-better-than-waffles.md with a one paragraph summary for why pancakes are better, \\\n",
    "make sure to address RS a student from my course who dared to say avocado waffles are better.\"\n",
    "\n",
    "prompt = prompt_with_function_information + user_prompt\n",
    "\n",
    "llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write_file(\"./pancakes-are-better-than-waffles.md\", \"Pancakes are better than waffles because they offer a fluffy texture that absorbs syrup and toppings beautifully, creating a delightful flavor experience in every bite. Unlike avocado waffles, which can be overly savory and may not satisfy a sweet tooth, pancakes provide a comforting sweetness that pairs perfectly with fruits, whipped cream, or even chocolate chips. RS, while we appreciate your love for avocado waffles, nothing quite matches the enjoyment of a stack of warm, buttery pancakes!\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_python_output(prompt: str):\n",
    "    return prompt.replace(\"```python\\n\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "clean_python_output(llm_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write_file(\"./pancakes-are-better-than-waffles.md\", \"Pancakes are undeniably better than waffles, RS! While some may argue that avocado waffles have a unique flavor, pancakes offer a fluffy, comforting texture that perfectly complements a variety of toppings, from fresh fruits to maple syrup. Their adaptability and classic appeal make them a quintessential breakfast choice that can satisfy any palate.\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = clean_python_output(llm_response(prompt))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a way to execute this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We connected LLM + FUNCTION via some simple PROMPT magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pancakes are undeniably better than waffles, RS! While some may argue that avocado waffles have a unique flavor, pancakes offer a fluffy, comforting texture that perfectly complements a variety of toppings, from fresh fruits to maple syrup. Their adaptability and classic appeal make them a quintessential breakfast choice that can satisfy any palate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-assistants",
   "language": "python",
   "name": "gpt-assistants"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
