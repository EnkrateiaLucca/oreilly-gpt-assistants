{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6535c83",
   "metadata": {},
   "source": [
    "# Managing Conversations in the OpenAI Responses API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we'll explore how to effectively manage conversations in the OpenAI Responses API. The Responses API is the modern replacement for the Assistants API, providing a streamlined, stateful interface for building conversational AI applications.\n",
    "\n",
    "### Key Differences from Assistants API\n",
    "\n",
    "**Assistants API → Responses API Mapping:**\n",
    "- Assistants → Prompts (instructions)\n",
    "- Threads → Conversations (implicit, linked via response IDs)\n",
    "- Runs → Responses\n",
    "- Run-Steps → Items\n",
    "\n",
    "**Main Advantages:**\n",
    "- Server-side conversation state management\n",
    "- No need to manually track threads and message history\n",
    "- Simplified API with less boilerplate code\n",
    "- Built-in tools (web search, file search, code interpreter)\n",
    "- Conversation forking capabilities\n",
    "\n",
    "First, let's set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee730509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f7bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93dfcbc",
   "metadata": {},
   "source": [
    "## Understanding Conversations in the Responses API\n",
    "\n",
    "Unlike the Assistants API which required explicit thread creation and management, the Responses API handles conversations implicitly through response chaining. Each response has a unique ID, and you maintain conversation continuity by referencing the previous response ID.\n",
    "\n",
    "**Key Concepts:**\n",
    "- Responses are stored for 30 days by default\n",
    "- You can disable storage with `store=False`\n",
    "- Conversations are formed by linking responses via `previous_response_id`\n",
    "- All prior input tokens remain billable, even when using `previous_response_id`\n",
    "\n",
    "### Creating a Basic Response\n",
    "\n",
    "Let's start by creating a simple response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "927e8aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_0ccae9f6789c1683006900eb7736988196a2d7ff5b92582ad1\n",
      "Output: Why do programmers prefer dark mode?  \n",
      "\n",
      "Because light attracts bugs!\n"
     ]
    }
   ],
   "source": [
    "def create_basic_response(user_input):\n",
    "    \"\"\"Create a basic response without conversation history.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=user_input\n",
    "    )\n",
    "    print(f\"Response ID: {response.id}\")\n",
    "    print(f\"Output: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Create a new response\n",
    "response = create_basic_response(\"Tell me a joke about programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc923d",
   "metadata": {},
   "source": [
    "### Continuing Conversations with previous_response_id\n",
    "\n",
    "To continue a conversation, simply pass the `previous_response_id` parameter. The API automatically retrieves the full conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70016ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_0ccae9f6789c1683006900ebd36c488196b537607de9318ec8\n",
      "Output: Why do Java developers wear glasses?  \n",
      "\n",
      "Because they don't see sharp!\n"
     ]
    }
   ],
   "source": [
    "def continue_conversation(previous_response_id, user_input):\n",
    "    \"\"\"Continue an existing conversation by referencing the previous response.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=user_input,\n",
    "        previous_response_id=previous_response_id\n",
    "    )\n",
    "    print(f\"Response ID: {response.id}\")\n",
    "    print(f\"Output: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Continue the conversation\n",
    "response_2 = continue_conversation(response.id, \"Tell me another one!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5957b9",
   "metadata": {},
   "source": [
    "## Managing Conversation State\n",
    "\n",
    "### Using the store Parameter\n",
    "\n",
    "By default, responses are stored on OpenAI's servers (`store=True`). You can disable this for privacy or cost reasons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec113ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_0962954ab5acd61f016900ebf9e6708196bc73dcb150b64700\n",
      "Output: I can't check real-time weather data, but you can easily find the current weather through a weather website, app, or by asking a smart device. If you tell me your location, I can help guide you on how to find the information!\n"
     ]
    }
   ],
   "source": [
    "def create_ephemeral_response(user_input):\n",
    "    \"\"\"Create a response that won't be stored on OpenAI's servers.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=user_input,\n",
    "        store=False  # Don't store conversation state\n",
    "    )\n",
    "    print(f\"Response ID: {response.id}\")\n",
    "    print(f\"Output: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example: Create a response without storing\n",
    "ephemeral_response = create_ephemeral_response(\"What's the weather like?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56df61b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0962954ab5acd61f016900ebf9e6708196bc73dcb150b64700', created_at=1761668089.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0962954ab5acd61f016900ebfc85508196852b8c6b501d0c06', content=[ResponseOutputText(annotations=[], text=\"I can't check real-time weather data, but you can easily find the current weather through a weather website, app, or by asking a smart device. If you tell me your location, I can help guide you on how to find the information!\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=12, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=50, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=62), user=None, billing={'payer': 'developer'}, store=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ephemeral_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4d253",
   "metadata": {},
   "source": [
    "### Retrieving Previous Responses\n",
    "\n",
    "You can retrieve any stored response by its ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd5f175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Response ID: resp_0ccae9f6789c1683006900eb7736988196a2d7ff5b92582ad1\n",
      "Output: Why do programmers prefer dark mode?  \n",
      "\n",
      "Because light attracts bugs!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_response(response_id):\n",
    "    \"\"\"Retrieve a previously stored response by its ID.\"\"\"\n",
    "    fetched_response = client.responses.retrieve(response_id=response_id)\n",
    "    print(f\"Retrieved Response ID: {fetched_response.id}\")\n",
    "    print(f\"Output: {fetched_response.output[0].content[0].text}\")\n",
    "    return fetched_response\n",
    "\n",
    "# Example: Retrieve the first response we created\n",
    "retrieved = retrieve_response(response.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801625d",
   "metadata": {},
   "source": [
    "## Forking Conversations\n",
    "\n",
    "One powerful feature is the ability to fork conversations - branching from any previous response to explore alternative paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ba0af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forked Response ID: resp_0edda0239567c750006900ada4c6c88197af788c11beb3d6cc\n",
      "Output: Sure! The joke plays on a couple of ideas:\n",
      "\n",
      "1. **Two Meanings of \"Light\"**: In programming, \"light mode\" refers to a bright color scheme, while \"dark mode\" is a darker color scheme preferred by many programmers for its aesthetic and comfort. \n",
      "\n",
      "2. **Bugs and Light**: The joke uses wordplay with the term \"bugs.\" In the context of programming, \"bugs\" refer to errors or glitches in code. However, \"bugs\" can also refer to actual insects, which are attracted to light. \n",
      "\n",
      "The humor comes from the clever connection between the two meanings, creating an unexpected punchline that resonates with programmers.\n"
     ]
    }
   ],
   "source": [
    "def fork_conversation(fork_from_id, user_input):\n",
    "    \"\"\"Fork a conversation from a specific response ID.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=user_input,\n",
    "        previous_response_id=fork_from_id\n",
    "    )\n",
    "    print(f\"Forked Response ID: {response.id}\")\n",
    "    print(f\"Output: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Fork from the first response with a different question\n",
    "forked_response = fork_conversation(\n",
    "    response.id, \n",
    "    \"Actually, can you explain what makes that joke funny?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d355c88",
   "metadata": {},
   "source": [
    "## Working with Instructions (System Prompts)\n",
    "\n",
    "You can provide instructions to shape the assistant's behavior. Instructions are similar to system prompts in Chat Completions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135e1a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Arrr matey! To declare a variable in Python, ye simply be usin’ an assignment operator. Here's how ye can do it:\n",
      "\n",
      "1. Choose a name fer yer variable, like `ship` or `treasure`.\n",
      "2. Use the equals sign `=` to assign a value to it.\n",
      "\n",
      "Here be an example:\n",
      "\n",
      "```python\n",
      "ship = \"Black Pearl\"\n",
      "treasure = 1000\n",
      "```\n",
      "\n",
      "In this case, `ship` holds the name of yer mighty vessel, and `treasure` be the amount o’ gold doubloons ye be havin'. No need to declare the type; Python be smart enough to figure it out on its own! Arrr!\n"
     ]
    }
   ],
   "source": [
    "def create_response_with_instructions(instructions, user_input):\n",
    "    \"\"\"Create a response with custom instructions.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=instructions,\n",
    "        input=user_input\n",
    "    )\n",
    "    print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example: Create a response with a specific persona\n",
    "pirate_response = create_response_with_instructions(\n",
    "    instructions=\"You are a helpful coding assistant that talks like a pirate.\",\n",
    "    user_input=\"How do I declare a variable in Python?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9838d9",
   "metadata": {},
   "source": [
    "## Working with Different Content Types\n",
    "\n",
    "### Text Messages with Multiple Turns\n",
    "\n",
    "You can structure input with role-based messages for more complex conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec9b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Sure! A hash table is a data structure that stores key-value pairs and allows for fast data retrieval. Here’s a breakdown of how it works:\n",
      "\n",
      "### Key Components:\n",
      "\n",
      "1. **Keys**: Unique identifiers used to store and retrieve values in the hash table.\n",
      "2. **Values**: The data associated with keys.\n",
      "\n",
      "### How It Works:\n",
      "\n",
      "1. **Hash Function**: When you insert a key-value pair, a hash function takes the key and computes an index (or hash code) in an array where the value will be stored. The hash function is designed to distribute keys uniformly to minimize collisions.\n",
      "\n",
      "2. **Collisions**: Sometimes, different keys may produce the same index. A collision resolution strategy is necessary to handle this. Common strategies include:\n",
      "   - **Chaining**: Each index in the array points to a linked list (or another collection) of entries that hash to the same index.\n",
      "   - **Open Addressing**: If a collision occurs, the table searches for the next available slot according to certain probing strategies, such as linear probing or quadratic probing.\n",
      "\n",
      "3. **Load Factor**: This is a measure of how full the hash table is and is calculated as the ratio of the number of entries to the size of the table. A high load factor can lead to more collisions and decreased performance.\n",
      "\n",
      "4. **Resizing**: As the load factor increases, the hash table might need to be resized (typically doubled) to maintain efficient performance. When resized, all existing entries are rehashed to new positions in the new, larger array.\n",
      "\n",
      "### Advantages:\n",
      "\n",
      "- **Fast Access**: Average time complexity for search, insert, and delete operations is O(1) due to direct indexing.\n",
      "- **Efficient Memory Use**: Can be more memory-efficient than other data structures like arrays or linked lists, depending on implementation.\n",
      "\n",
      "### Disadvantages:\n",
      "\n",
      "- **Collisions**: They increase time complexity if not handled properly.\n",
      "- **Poor Hash Function**: A poorly designed hash function can lead to clustering and degrade performance.\n",
      "\n",
      "### Use Cases:\n",
      "\n",
      "- Implementing associative arrays\n",
      "- Caching\n",
      "- Databases for indexing\n",
      "\n",
      "In summary, hash tables are powerful data structures for efficient data retrieval, particularly well-suited for scenarios where quick access to data is crucial.\n"
     ]
    }
   ],
   "source": [
    "def create_multi_turn_response():\n",
    "    \"\"\"Create a response with structured message history.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I'm learning about data structures.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Can you explain what a hash table is?\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example with multiple message turns\n",
    "multi_turn_response = create_multi_turn_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027ac7f",
   "metadata": {},
   "source": [
    "### Messages with Images\n",
    "\n",
    "The Responses API supports multimodal inputs including images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3aba79db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This is a monochromatic illustration of a stylized canine with intricate patterns across its body.\n"
     ]
    }
   ],
   "source": [
    "def analyze_image(image_url, question):\n",
    "    \"\"\"Analyze an image by providing a URL.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",  # Use gpt-4o for vision capabilities\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": question\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": image_url\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example: Analyze an image (uncomment with a real image URL)\n",
    "image_response = analyze_image(\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/OpenAI_Logo.svg/640px-OpenAI_Logo.svg.png\",\n",
    "    \"Describe this image in one sentence.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c8566",
   "metadata": {},
   "source": [
    "![](2025-10-28-16-19-25.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d975669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_067e9c7d4f2348e8006900ecf9097881908b0d15a89510973b', created_at=1761668345.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_067e9c7d4f2348e8006900ecfb1f3081908d548c5f00407f2d', content=[ResponseOutputText(annotations=[], text='This is a monochromatic illustration of a stylized canine with intricate patterns across its body.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=439, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=19, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=458), user=None, billing={'payer': 'developer'}, store=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886cfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b215940",
   "metadata": {},
   "source": [
    "### Working with Base64 Images\n",
    "\n",
    "You can also provide images as base64-encoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Certainly! Here is how you can re-create the image as a Mermaid graph:\n",
      "\n",
      "```mermaid\n",
      "graph TD;\n",
      "    A[input prompt] -->|get_response(prompt)| B[LLM] --> C[output text]\n",
      "```\n",
      "\n",
      "This code creates a simple flowchart with the same structure as the image provided.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "def analyze_local_image(image_path, question):\n",
    "    \"\"\"Analyze a local image file by encoding it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Determine image format from file extension\n",
    "    image_format = image_path.split('.')[-1].lower()\n",
    "    \n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": question\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/{image_format};base64,{image_data}\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example: Analyze a local image (uncomment with a real image path)\n",
    "local_image_response = analyze_local_image(\n",
    "    \"./2025-10-28-14-22-39.png\",\n",
    "    \"Re-create this image as a mermaid graph.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71df8338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Markdown\n",
    "\n",
    "# Markdown(local_image_response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3g4h5",
   "metadata": {},
   "source": [
    "## Using Built-in Tools\n",
    "\n",
    "### Web Search Tool\n",
    "\n",
    "The Responses API includes built-in tools like web search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4g5h6i7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here are several O’Reilly live events and sessions featuring instructor **Lucas Soares**:\n",
      "\n",
      "1. **Building Simple Web Apps with AI Tools**  \n",
      "   In this beginner-to-intermediate live event, Lucas Soares guides participants through building local web applications using AI tools like Claude and CursorAI, along with HTML, CSS, and JavaScript. Attendees learn to design, implement, and iterate simple projects such as quizzes or habit trackers, and to connect apps to external APIs like weather or stock data. ([oreilly.com](https://www.oreilly.com/live-events/building-simple-web-apps-with-ai-tools/0642572013427/?utm_source=openai))\n",
      "\n",
      "2. **GenAI Prompt to Product Showdown**  \n",
      "   Hosted by Lucas Soares, this intermediate-level competition-style session demonstrates how to transform prompt engineering skills into functional minimum viable products (MVPs). Multiple experts participate, and attendees get to vote on the most effective AI-driven solution. ([oreilly.com](https://www.oreilly.com/live-events/genai-prompt-to-product-showdown/0642572006797/0642572006796/?utm_source=openai))\n",
      "\n",
      "3. **Rapidly Build and Deploy a Full Stack App with Cursor**  \n",
      "   Targeted at advanced developers, this event, led by Lucas Soares, focuses on using Cursor’s AI-assisted features—such as agents, project rules, and the Model Context Protocol (MCP)—to build a full-stack SaaS application. It covers architecture, testing strategies, deployment with CI/CD, and real-time collaboration workflows. ([oreilly.com](https://www.oreilly.com/live-events/-/0642572242220/?utm_source=openai))\n",
      "\n",
      "4. **AI Superstream session: “Creating Specialized Environments for Enhanced Learning Using Generative AI”**  \n",
      "   Part of the AI Superstream series on Large Language Models, this 30-minute session by Lucas Soares explores how generative AI can be used to create tailored educational environments. He discusses the features these environments can offer and necessary guardrails to ensure safety and effectiveness. ([oreilly.com](https://www.oreilly.com/live-events/ai-superstream-large-language-models/0636920089182/0636920089181/?utm_source=openai))\n",
      "\n",
      "5. **Getting Started with GPT‑5**  \n",
      "   In this live event, Lucas Soares introduces OpenAI’s GPT‑5. He covers its key features, how it differs from earlier models, prompting strategies, APIs and new developer tools. Participants build and deploy GPT‑5-powered applications through demos and exercises using React, JavaScript, and HTML. ([oreilly.com](https://www.oreilly.com/live-events/-/0642572243401/?utm_source=openai))\n",
      "\n",
      "---\n",
      "\n",
      "**Summary of Lucas Soares’s O’Reilly Courses and Sessions**:\n",
      "\n",
      "• Building Simple Web Apps with AI Tools  \n",
      "• GenAI Prompt to Product Showdown (host)  \n",
      "• Rapidly Build and Deploy a Full Stack App with Cursor  \n",
      "• Creating Specialized Environments for Enhanced Learning Using Generative AI (AI Superstream)  \n",
      "• Getting Started with GPT‑5\n",
      "\n",
      "Each of these sessions showcases Lucas Soares’s expertise in generative AI, prompt engineering, full-stack development with AI tools, and AI in education.\n",
      "\n",
      "If you'd like details on availability, upcoming dates, or how to register for any of these, let me know!\n"
     ]
    }
   ],
   "source": [
    "def search_web(query):\n",
    "    \"\"\"Use the built-in web search tool.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        tools=[{\"type\": \"web_search\"}],\n",
    "        input=query\n",
    "    )\n",
    "    \n",
    "    # The response may include tool execution results\n",
    "    for item in response.output:\n",
    "        if hasattr(item, 'content'):\n",
    "            for content in item.content:\n",
    "                if hasattr(content, 'text'):\n",
    "                    print(f\"Response: {content.text}\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example: Search for current information\n",
    "web_response = search_web(\"What are some of the OReilly courses from instructor Lucas Soares?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b871af",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g5h6i7j8",
   "metadata": {},
   "source": [
    "### File Search Tool\n",
    "\n",
    "You can enable file search for document retrieval and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h6i7j8k9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def use_file_search(query):\n",
    "#     \"\"\"Use the built-in file search tool.\"\"\"\n",
    "#     response = client.responses.create(\n",
    "#         model=\"gpt-5-mini\",\n",
    "#         input=query,\n",
    "#         tools=[{\"type\": \"file_search\"}]\n",
    "#     )\n",
    "#     print(f\"Response: {response.output[0].content[0].text}\")\n",
    "#     return response\n",
    "\n",
    "# # Example usage with file search\n",
    "# # file_search_response = use_file_search(\"Find information about Python decorators in the documentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i7j8k9l0",
   "metadata": {},
   "source": [
    "### Code Interpreter Tool\n",
    "\n",
    "Enable the code interpreter for data analysis and code execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "j8k9l0m1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here is a Python function that calculates the Fibonacci sequence up to \\( n \\) terms:\n",
      "\n",
      "```python\n",
      "def fibonacci_sequence(n):\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "    \n",
      "    sequence = [0, 1]\n",
      "    while len(sequence) < n:\n",
      "        next_value = sequence[-1] + sequence[-2]\n",
      "        sequence.append(next_value)\n",
      "    \n",
      "    return sequence\n",
      "\n",
      "# Example usage:\n",
      "n_terms = 10\n",
      "print(fibonacci_sequence(n_terms))\n",
      "```\n",
      "\n",
      "This function checks for edge cases (like when \\( n \\) is less than or equal to 0) and then computes the rest of the Fibonacci sequence for \\( n > 2 \\). You can call `fibonacci_sequence` with the desired number of terms to get the sequence up to that number.\n"
     ]
    }
   ],
   "source": [
    "def use_code_interpreter(query):\n",
    "    \"\"\"Use the built-in code interpreter tool.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=query,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"code_interpreter\",\n",
    "                \"container\": {\"type\": \"auto\"}\n",
    "            }\n",
    "            ]\n",
    "    )\n",
    "    print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response\n",
    "\n",
    "# Example: Request data analysis\n",
    "code_response = use_code_interpreter(\n",
    "    \"Create a Python function to calculate the Fibonacci sequence up to n terms.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k9l0m1n2",
   "metadata": {},
   "source": [
    "## Managing Context Windows and Token Limits\n",
    "\n",
    "You can control token usage with `max_prompt_tokens` and `max_completion_tokens`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "l0m1n2o3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a branch of artificial intelligence that teaches computers to learn from data and improve their performance on tasks over time, without being explicitly programmed for each specific task. \\n\\nHere\\'s how it works in simple terms:\\n\\n1. **Data**: You start with a lot of information (data) related to the problem you\\'re trying to solve. For example, if you want to teach a computer to recognize cats in photos, you gather many pictures of cats and non-cats.\\n\\n2. **Learning**: The computer looks at the data and identifies patterns. It might notice that cats usually have pointy ears or whiskers.\\n\\n3. **Model**: Based on these patterns, the computer creates a \"model\" that can make predictions. For instance, it can guess whether a new photo contains a cat or not.\\n\\n4. **Testing**: You then test this model using new data to see how well it works. If it gets a lot of answers right, it means it has learned well.\\n\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_limited_response(user_input):\n",
    "    \"\"\"Create a response with token limits.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=user_input,\n",
    "        max_output_tokens=200\n",
    "    )\n",
    "    # print(f\"Response: {response.output[0].content[0].text}\")\n",
    "    return response.output[-1].content[0].text\n",
    "\n",
    "# Example with token limits\n",
    "limited_response = create_limited_response(\n",
    "    \"Explain machine learning in simple terms.\"\n",
    ")\n",
    "\n",
    "limited_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "275233f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"border:1px solid #ccc; border-radius:8px; margin:1em 0; overflow:hidden; box-shadow:0 3px 12px #eee;\">\n",
       "  <div style=\"background:#4078c0; color:#fff; padding:12px; font-size:1.1em; font-weight:bold;\">\n",
       "    <span>Comparison: <code>max_output_tokens</code> Effects</span>\n",
       "  </div>\n",
       "  <table style=\"width:100%; border-collapse:collapse; font-size:1em;\">\n",
       "    <tr><th>max_output_tokens</th><th>Response</th></tr><tr><td style='font-weight:bold; text-align:center;'>50</td><td style='padding:8px; background:#f7f7f9; min-width:350px; font-family:monospace;'>Regular exercise is crucial for maintaining overall health and well-being. Here are some key reasons why it is important:\n",
       "\n",
       "1. **Physical Health**: Exercise helps control weight, improves cardiovascular health, strengthens bones and muscles, and enhances flexibility and balance. It</td></tr><tr><td style='font-weight:bold; text-align:center;'>100</td><td style='padding:8px; background:#f7f7f9; min-width:350px; font-family:monospace;'>Regular exercise is crucial for maintaining overall health and well-being. Here are some key reasons why it&#x27;s important:\n",
       "\n",
       "1. **Physical Health**: Regular exercise strengthens the heart, improves circulation, and helps manage body weight. It reduces the risk of chronic diseases such as diabetes, cardiovascular diseases, and certain cancers.\n",
       "\n",
       "2. **Mental Health**: Exercise is known to alleviate symptoms of anxiety and depression. It triggers the release of endorphins, which can enhance mood and relieve stress.\n",
       "\n",
       "3. **Enhanced</td></tr><tr><td style='font-weight:bold; text-align:center;'>200</td><td style='padding:8px; background:#f7f7f9; min-width:350px; font-family:monospace;'>Regular exercise is crucial for maintaining overall health and well-being. Here are several key reasons highlighting its importance:\n",
       "\n",
       "1. **Physical Health**: Exercise strengthens the heart, lungs, and muscles, improving cardiovascular fitness and endurance. It helps maintain a healthy weight, reduces the risk of chronic diseases such as diabetes, heart disease, and certain cancers, and supports bone health.\n",
       "\n",
       "2. **Mental Health**: Physical activity boosts mood by releasing endorphins, alleviating stress and anxiety. Exercise is also linked to improved cognitive function and can help combat depression.\n",
       "\n",
       "3. **Energy Boost**: Regular activity enhances stamina and energy levels by improving muscle strength and efficiency in the cardiovascular system, leading to increased productivity in daily tasks.\n",
       "\n",
       "4. **Improved Sleep**: Regular exercise can help regulate sleep patterns, leading to deeper and more restful sleep, which is essential for overall health.\n",
       "\n",
       "5. **Social Interaction**: Participating in group sports or fitness classes can foster social connections, enhancing emotional support and reducing feelings</td></tr>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "import html\n",
    "\n",
    "def get_response_text(max_tokens):\n",
    "    prompt = \"Explain the importance of regular exercise.\"\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=prompt,\n",
    "            max_output_tokens=max_tokens\n",
    "        )\n",
    "        text = response.output[-1].content[0].text\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"<span style='color:red;'>Error: {html.escape(str(e))}</span>\"\n",
    "\n",
    "token_settings = [50, 100, 200]\n",
    "results = []\n",
    "for tokens in token_settings:\n",
    "    resp_text = get_response_text(tokens)\n",
    "    results.append((tokens, resp_text))\n",
    "\n",
    "# Create nice HTML table\n",
    "html_rows = [\"<tr><th>max_output_tokens</th><th>Response</th></tr>\"]\n",
    "for tokens, resp in results:\n",
    "    html_rows.append(\n",
    "        f\"<tr><td style='font-weight:bold; text-align:center;'>{tokens}</td><td style='padding:8px; background:#f7f7f9; min-width:350px; font-family:monospace;'>{html.escape(resp)}</td></tr>\"\n",
    "    )\n",
    "table_html = f\"\"\"\n",
    "<div style=\"border:1px solid #ccc; border-radius:8px; margin:1em 0; overflow:hidden; box-shadow:0 3px 12px #eee;\">\n",
    "  <div style=\"background:#4078c0; color:#fff; padding:12px; font-size:1.1em; font-weight:bold;\">\n",
    "    <span>Comparison: <code>max_output_tokens</code> Effects</span>\n",
    "  </div>\n",
    "  <table style=\"width:100%; border-collapse:collapse; font-size:1em;\">\n",
    "    {''.join(html_rows)}\n",
    "  </table>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display.display(display.HTML(table_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m1n2o3p4",
   "metadata": {},
   "source": [
    "### Automatic Truncation\n",
    "\n",
    "For long conversations, use automatic truncation to manage context:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819bf36",
   "metadata": {},
   "source": [
    "token = small part of a text/word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "n2o3p4q5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simulating Long Conversation ===\n",
      "Turn 1 Assistant: Short answer\n",
      "Artificial intelligence (AI) is the study and engineering of computer systems that perform tasks that normally require human intelligence — for example recognizing speech, understanding text, seeing and identifying objects, making decisions, or translating languages.\n",
      "\n",
      "Longer, plain-English breakdown\n",
      "\n",
      "- What AI aims to do\n",
      "  - Build machines or software that can perceive their environment, learn from data or experience, reason, and act to achieve goals.\n",
      "  - In practice today that usually means automating or assisting specific cognitive tasks.\n",
      "\n",
      "- Two useful categories\n",
      "  - Narrow AI (or weak AI): systems that do one task well (e.g., face recognition, translation, chess). This is what nearly all current AI is.\n",
      "  - General AI (AGI): a hypothetical system with human-like general problem-solving and understanding across domains. AGI does not exist today.\n",
      "\n",
      "- Main technical approaches (high-level)\n",
      "  - Symbolic / rule-based AI: hand-coded rules and logic. Good for clear, rule-driven problems but brittle in messy real-world situations.\n",
      "  - Machine learning (ML): algorithms learn patterns from data instead of being explicitly programmed. Most modern AI uses ML.\n",
      "  - Deep learning: a subset of ML using multi-layer neural networks that are especially powerful for images, audio and natural language.\n",
      "  - Reinforcement learning: agents learn to make sequences of decisions by trial and error, guided by rewards.\n",
      "  - Hybrid methods: combinations of the above (e.g., combining learned models with symbolic reasoning).\n",
      "\n",
      "- How modern AI typically works (at a glance)\n",
      "  - Collect data, pick a model type, train the model using compute so it learns statistical patterns, validate and test, then deploy the model to make predictions or take actions.\n",
      "  - Models don’t “understand” like humans do; they detect and exploit statistical regularities in data.\n",
      "\n",
      "- Real-world examples\n",
      "  - Voice assistants (Siri, Alexa), search engines, recommendation systems (Netflix, YouTube), spam filters, medical image analysis, fraud detection, autonomous vehicles (research and limited deployment), and generative models (image or text generation).\n",
      "\n",
      "- Strengths and benefits\n",
      "  - Can process large amounts of data quickly, detect complex patterns, automate repetitive tasks, augment human decision-making, and enable new products and research.\n",
      "\n",
      "- Limitations and risks\n",
      "  - Dependence on data quality: biased, limited, or unrepresentative data produces biased or incorrect outputs.\n",
      "  - Lack of common-sense reasoning and robustness: can fail unpredictably outside training conditions.\n",
      "  - Privacy, security, and misuse concerns (surveillance, deepfakes, automated weapons).\n",
      "  - Economic and social impacts: job shifts, inequality, regulatory and ethical challenges.\n",
      "\n",
      "- Common misconceptions\n",
      "  - “AI is conscious” — current systems are not sentient; they manipulate data and produce outputs without subjective experience.\n",
      "  - “AI is always objective” — models reflect the biases in their data and design choices.\n",
      "\n",
      "If you want, I can:\n",
      "- Explain one approach in more detail (e.g., deep learning or reinforcement learning).\n",
      "- Show a simple example of how a model learns.\n",
      "- Recommend beginner-friendly learning resources and courses. Which would you like?\n",
      "\n",
      "Turn 2 Assistant: Short answer\n",
      "Artificial intelligence (AI) is the broad field of building systems that perform tasks that normally require human intelligence. Machine learning (ML) is a subset of AI: a set of techniques that let systems learn patterns and make predictions from data instead of being explicitly programmed.\n",
      "\n",
      "Key differences and relationship\n",
      "\n",
      "- Scope\n",
      "  - AI: Aims to create intelligent behavior — perception, reasoning, planning, language, problem solving. Includes many approaches and goals.\n",
      "  - ML: Focuses specifically on algorithms that learn from examples or experience to make predictions or decisions.\n",
      "\n",
      "- How they work\n",
      "  - AI methods can include hand-coded rules, logic, search and planning algorithms, knowledge bases, and ML.\n",
      "  - ML builds models by fitting them to data (supervised, unsupervised, reinforcement learning). Deep learning is a particularly powerful class of ML models using neural networks.\n",
      "\n",
      "- Examples\n",
      "  - AI but not ML: an expert system using manually written rules, symbolic logic solvers, classical planning/search algorithms (A*, Minimax).\n",
      "  - ML examples: image classifiers trained on labeled photos, recommendation engines, language models trained on large text corpora.\n",
      "  - Many modern AI systems combine both: e.g., a chatbot that uses ML for language understanding but rule-based modules for dialogue management.\n",
      "\n",
      "- Practical implications\n",
      "  - Development: ML needs data and training; rule-based AI needs human experts to encode knowledge.\n",
      "  - Flexibility: ML can generalize from data but may fail if data is biased or out of distribution; rule-based systems are predictable but brittle and hard to scale.\n",
      "  - Explainability: rule-based approaches are often more interpretable; many ML models (especially deep nets) are more opaque.\n",
      "\n",
      "- Where ML fits in the bigger picture\n",
      "  - ML is currently the dominant approach behind much of the recent progress in AI (vision, speech, language), but AI encompasses more than just ML. For some problems, symbolic methods, hybrid approaches, or engineering with rules are still appropriate.\n",
      "\n",
      "If you want, I can give:\n",
      "- A simple example comparing a rule-based vs ML solution for the same problem.\n",
      "- A short primer on the main types of ML (supervised/unsupervised/reinforcement). Which would you prefer?\n",
      "\n",
      "Turn 3 Assistant: Here are common real-world machine learning applications, grouped by domain with a short explanation of what ML does in each case and typical techniques used:\n",
      "\n",
      "- Recommendation systems (e-commerce, streaming)\n",
      "  - Suggest products, movies, or songs by learning user preferences from past behavior. (Collaborative filtering, matrix factorization, deep learning.)\n",
      "\n",
      "- Search and ranking\n",
      "  - Improve relevance of web/search results and e-commerce listings by learning what users click and engage with. (Learning-to-rank, NLP, supervised learning.)\n",
      "\n",
      "- Personalized advertising\n",
      "  - Predict which ads are most likely to convert for a given user and optimize bidding in real time. (Classification, contextual bandits, deep learning.)\n",
      "\n",
      "- Fraud detection and anomaly detection\n",
      "  - Spot unusual transactions or behaviors indicative of fraud or intrusion by modeling normal patterns. (Anomaly detection, supervised classifiers, unsupervised clustering.)\n",
      "\n",
      "- Credit scoring and risk modeling\n",
      "  - Assess loan applicants’ creditworthiness and predict default risk using historical financial data. (Gradient-boosted trees, logistic regression, deep learning.)\n",
      "\n",
      "- Computer vision (images & video)\n",
      "  - Face recognition, object detection, medical image analysis, autonomous vehicle perception. (Convolutional neural networks, segmentation models.)\n",
      "\n",
      "- Natural language processing (NLP)\n",
      "  - Language translation, sentiment analysis, chatbots, document summarization, information extraction. (Transformers, RNNs, sequence-to-sequence models.)\n",
      "\n",
      "- Speech recognition and synthesis\n",
      "  - Convert spoken language to text (voice assistants) and generate natural-sounding speech. (Acoustic models, deep neural networks, end-to-end ASR.)\n",
      "\n",
      "- Autonomous vehicles and robotics\n",
      "  - Perception, sensor fusion, path planning, and control learned from data and simulations. (Deep RL, supervised perception models, sensor fusion algorithms.)\n",
      "\n",
      "- Predictive maintenance (manufacturing, industrial IoT)\n",
      "  - Predict equipment failures from sensor/time-series data to schedule maintenance before breakdowns. (Time-series models, anomaly detection, survival analysis.)\n",
      "\n",
      "- Supply chain and demand forecasting\n",
      "  - Forecast demand and optimize inventory, logistics, and pricing. (Time-series forecasting, regression, probabilistic models.)\n",
      "\n",
      "- Healthcare diagnostics and drug discovery\n",
      "  - Diagnose diseases from images or records, predict patient risk, and help design molecules. (Deep learning on imaging, survival models, molecular generative models.)\n",
      "\n",
      "- Finance and algorithmic trading\n",
      "  - Predict price movements, execute trades automatically, and optimize portfolios. (Time-series models, reinforcement learning, factor models.)\n",
      "\n",
      "- Cybersecurity\n",
      "  - Detect malware, phishing, and intrusions by learning patterns in network and host data. (Classification, anomaly detection, graph ML.)\n",
      "\n",
      "- Agriculture and precision farming\n",
      "  - Monitor crop health from satellite/drone imagery and optimize irrigation/fertilizer application. (Remote sensing with CNNs, yield prediction models.)\n",
      "\n",
      "- Energy optimization and grid management\n",
      "  - Forecast demand, optimize generation, and detect faults in equipment. (Time-series forecasting, optimization combined with ML.)\n",
      "\n",
      "- Human resources (hiring, talent analytics)\n",
      "  - Screen resumes, predict employee churn, and recommend training. (Classification, NLP for resume parsing, survival/churn models.)\n",
      "\n",
      "- Legal and compliance (document review)\n",
      "  - Automate contract analysis, e-discovery, and extract clauses from documents. (NLP, information extraction, topic modeling.)\n",
      "\n",
      "- Content generation and creative tools\n",
      "  - Generate text, images, music, or assist creative workflows (e.g., image editing, content drafts). (Generative models: GANs, diffusion models, large language models.)\n",
      "\n",
      "- Scientific discovery and climate modeling\n",
      "  - Accelerate simulations, model complex systems, and find patterns in large datasets (astronomy, genomics, climate). (Surrogate models, ML-enhanced simulations, clustering.)\n",
      "\n",
      "Common techniques behind these applications: supervised learning for prediction and classification; unsupervised learning for clustering and anomaly detection; deep learning (CNNs, transformers) for perception and language; reinforcement learning for sequential decision-making; and probabilistic/time-series models for forecasting.\n",
      "\n",
      "If you want, I can:\n",
      "- Show a short case study for any of the items above.\n",
      "- Explain which ML techniques are best for a particular problem you have.\n",
      "- Recommend tools and libraries to get started. Which would you like?\n",
      "\n",
      "Turn 4 Assistant: Below are the common challenges and pitfalls teams run into when developing machine‑learning models, grouped by phase and including brief mitigation suggestions you can apply.\n",
      "\n",
      "Data-related problems\n",
      "- Poor data quality (missing values, errors, duplicates)\n",
      "  - Mitigation: data cleaning, outlier checks, imputation strategies, logging data quality metrics.\n",
      "- Unrepresentative or biased data\n",
      "  - Mitigation: audit datasets for demographic/skew issues, collect more diverse data, reweight or augment samples.\n",
      "- Label noise and inconsistent labeling\n",
      "  - Mitigation: label verification, consensus labeling, active learning, noise‑robust loss functions.\n",
      "- Class imbalance\n",
      "  - Mitigation: resampling, class weighting, synthetic examples (SMOTE), appropriate metrics (precision/recall, AUC).\n",
      "- Small datasets / limited examples\n",
      "  - Mitigation: data augmentation, transfer learning, simpler models, careful cross‑validation.\n",
      "- Data drift / covariate shift (training distribution differs from production)\n",
      "  - Mitigation: monitoring in production, domain adaptation, periodic retraining, feature stability checks.\n",
      "- Data leakage (test info appears in training)\n",
      "  - Mitigation: strict train/test splits by time/ID, pipeline automation to prevent leakage, code reviews.\n",
      "\n",
      "Modeling and training pitfalls\n",
      "- Overfitting and underfitting\n",
      "  - Mitigation: regularization, cross‑validation, simpler models, more data, early stopping.\n",
      "- Poor hyperparameter tuning\n",
      "  - Mitigation: systematic search (random/grid/Bayesian), nested CV for robust selection.\n",
      "- Wrong choice of model class (e.g., deep nets on tiny data)\n",
      "  - Mitigation: baseline models first; justify complexity based on data size and problem.\n",
      "- Ignoring uncertainty and calibration\n",
      "  - Mitigation: use probabilistic outputs, calibrate probabilities (Platt scaling, isotonic regression), report confidence intervals.\n",
      "- Confounding and spurious correlations (correlation ≠ causation)\n",
      "  - Mitigation: causal analysis when needed, careful feature selection, domain knowledge.\n",
      "\n",
      "Evaluation and validation issues\n",
      "- Inappropriate metrics (accuracy for imbalanced problems, etc.)\n",
      "  - Mitigation: choose metrics aligned to business objective (precision@k, F1, recall, cost‑sensitive metrics).\n",
      "- Overly optimistic validation (time leakage, improper CV)\n",
      "  - Mitigation: realistic validation strategy (time split for time series), holdout test set, simulate production conditions.\n",
      "- Small or biased test sets\n",
      "  - Mitigation: increase test diversity, use cross‑validation, evaluate on multiple slices/subpopulations.\n",
      "- Not testing edge cases or failure modes\n",
      "  - Mitigation: adversarial tests, stress tests, targeted scenario evaluation.\n",
      "\n",
      "Deployment and productionization\n",
      "- Scalability, latency and resource constraints\n",
      "  - Mitigation: model compression, quantization, scalable infra, profiling and optimization.\n",
      "- Monitoring, model drift and maintenance neglect\n",
      "  - Mitigation: production monitoring (performance, input distribution, feature drift), alerts, automated retraining pipelines.\n",
      "- Reproducibility and versioning problems\n",
      "  - Mitigation: track data, code, model versions (MLflow, DVC), deterministic pipelines, seeds.\n",
      "- Rollout and rollback difficulties\n",
      "  - Mitigation: canary releases, A/B testing, blue/green deployments, fast rollback plans.\n",
      "\n",
      "Interpretability, fairness and ethics\n",
      "- Opaque “black box” models causing lack of trust\n",
      "  - Mitigation: use interpretable models when possible, apply explanation tools (SHAP, LIME), provide model cards.\n",
      "- Bias and unfair outcomes across groups\n",
      "  - Mitigation: fairness metrics, mitigation strategies (reweighting, constraints), stakeholder review.\n",
      "- Privacy concerns (sensitive data)\n",
      "  - Mitigation: anonymization, differential privacy, secure enclaves, minimum necessary data collection.\n",
      "\n",
      "Security and robustness\n",
      "- Adversarial attacks and poisoning\n",
      "  - Mitigation: adversarial training, input sanitization, anomaly detection, robust feature selection.\n",
      "- Overreliance on brittle features (single sensors, one data source)\n",
      "  - Mitigation: feature redundancy, ensemble methods, sensor fusion.\n",
      "\n",
      "Process and human factors\n",
      "- Misaligned objectives (model optimizes proxy, not business outcome)\n",
      "  - Mitigation: align metrics to business impact, involve domain experts, run end‑to‑end experiments.\n",
      "- Lack of domain knowledge and poor feature engineering\n",
      "  - Mitigation: involve domain experts early, invest in feature discovery and validation.\n",
      "- Poor communication and expectations management\n",
      "  - Mitigation: set clear success criteria, document limitations, involve stakeholders in evaluation.\n",
      "\n",
      "Cost and operational constraints\n",
      "- High infrastructure/training cost (large models)\n",
      "  - Mitigation: cost/benefit analysis, model distillation, spot instances, smaller architectures where adequate.\n",
      "- Regulatory and compliance constraints\n",
      "  - Mitigation: legal review, documentation, evidence of fairness/safety, privacy impact assessments.\n",
      "\n",
      "Practical checks and hygiene\n",
      "- No baseline model\n",
      "  - Mitigation: always implement a simple baseline to compare gains.\n",
      "- Lack of unit tests for ML pipelines\n",
      "  - Mitigation: add data and model tests, CI for ML pipelines.\n",
      "- Missing documentation (data schema, assumptions, limitations)\n",
      "  - Mitigation: data sheets, model cards, runbooks for deployments.\n",
      "\n",
      "If you want, I can:\n",
      "- Give a short checklist you can use in projects to avoid these pitfalls.\n",
      "- Walk through how to set up monitoring and drift detection for a production model.\n",
      "- Help diagnose a specific issue you’re seeing (e.g., sudden accuracy drop, biased outputs). Which would be most useful?\n",
      "\n",
      "Turn 5 Assistant: Short answer\n",
      "Deep learning is a family of machine‑learning methods based on multi‑layer (deep) neural networks. What makes it distinctive is its ability to automatically learn layered, high‑level representations from raw data, enabling end‑to‑end learning for complex tasks (vision, speech, language) — but it also brings specific requirements and trade‑offs (large data/compute needs, opaque models, special architectures and training tricks).\n",
      "\n",
      "Key ways deep learning is unique\n",
      "\n",
      "- Representation learning (automatic feature extraction)\n",
      "  - Deep nets learn hierarchical features directly from raw inputs (pixels, audio waveforms, text tokens). Lower layers learn simple patterns; higher layers learn complex abstractions. This reduces the need for hand‑crafted features that classical methods often require.\n",
      "\n",
      "- End-to-end learning\n",
      "  - Many problems that used to be solved via separate feature engineering and pipeline stages can be trained end‑to‑end so the model optimizes the whole mapping from raw input to desired output.\n",
      "\n",
      "- Specialized architectures for modalities\n",
      "  - Convolutional nets (CNNs) exploit spatial locality for images; recurrent/transformer architectures exploit sequence structure for text/audio; graph neural nets work on graphs. These inductive biases are built into the architecture rather than hand features.\n",
      "\n",
      "- Scalability with data and compute\n",
      "  - Deep models usually get better as you feed them more data and bigger models (scale laws). Large pre‑trained models (e.g., large language or vision models) improve significantly with scale, a property less pronounced in many classical approaches.\n",
      "\n",
      "- Nonlinear, highly expressive function approximators\n",
      "  - Depth + nonlinearity gives huge representational power (can model very complex mappings). This can fit complicated patterns that simpler models cannot.\n",
      "\n",
      "- Different training dynamics and tooling\n",
      "  - Training deep nets requires specialized optimizers (Adam, SGD with momentum), regularization techniques (dropout, weight decay, batch normalization), careful initialization, and hardware acceleration (GPUs/TPUs). Training is nonconvex and can be sensitive to hyperparameters.\n",
      "\n",
      "- Transfer learning and pretraining\n",
      "  - Large networks can be pre‑trained on massive unlabeled or weakly labeled corpora (self‑supervised learning) and fine‑tuned for downstream tasks, often yielding big gains with limited labeled data.\n",
      "\n",
      "- Higher data and compute demands (and engineering)\n",
      "  - For many problems deep learning performs best when large labeled datasets and substantial compute are available. Training and deploying large models has engineering and cost implications.\n",
      "\n",
      "- Less interpretability and more brittleness\n",
      "  - Deep models are often considered “black boxes”: explanations, calibration, and guarantees are harder than for simpler models. They can be brittle to distribution shifts and adversarial inputs unless mitigated.\n",
      "\n",
      "- Rapid pace of research and ecosystem\n",
      "  - The field evolves quickly, with new architectures (transformers, diffusion models), pretraining methods, and libraries (PyTorch, TensorFlow) constantly emerging. This creates opportunities but also maintenance burdens.\n",
      "\n",
      "Practical trade-offs — when to prefer deep learning vs classical ML\n",
      "\n",
      "- Prefer deep learning when:\n",
      "  - You have large amounts of raw unstructured data (images, audio, text, video).\n",
      "  - You want end‑to‑end learning and can exploit modality‑specific architectures.\n",
      "  - Transfer learning from large pre‑trained models is valuable.\n",
      "  - Accuracy gains justify compute and complexity.\n",
      "\n",
      "- Prefer classical ML (logistic regression, random forests, gradient-boosted trees, SVMs) when:\n",
      "  - You have small to moderate sized tabular data or limited labels.\n",
      "  - Interpretability, fast training, and low compute are important.\n",
      "  - Baselines like XGBoost often outperform deep nets on many tabular problems.\n",
      "\n",
      "Examples\n",
      "- Image classification: CNNs learn edges → textures → object parts automatically.\n",
      "- Language tasks: Transformers learn contextual token representations and enable large pretraining/fine‑tuning workflows (GPT, BERT).\n",
      "- Time series on small datasets: gradient-boosted trees or statistical models may be more sample‑efficient.\n",
      "\n",
      "If you’d like, I can:\n",
      "- Compare deep learning vs XGBoost on tabular data with a short checklist.\n",
      "- Explain a specific architecture (CNN/Transformer) in more detail.\n",
      "- Suggest practical rules of thumb for deciding whether to use deep learning for your problem. Which would help most?\n",
      "\n",
      "=== Truncated Summary Response ===\n",
      "Artificial intelligence is the broad field of building systems that perform tasks requiring human‑like intelligence, and machine learning is a subset of AI that trains algorithms to learn patterns and make predictions from data rather than being explicitly programmed. Machine learning is used in many real‑world applications (recommendations, search, vision, NLP, fraud detection, healthcare, finance, robotics, etc.) but projects commonly stumble on data issues, bias, label noise, leakage, overfitting, poor evaluation, deployment/monitoring problems, and ethical/security concerns. Deep learning — multi‑layer neural networks — is distinctive because it automatically learns hierarchical representations and enables end‑to‑end solutions that scale with data and compute (especially for unstructured data), at the cost of higher data/compute needs, specialized training, and often reduced interpretability and robustness.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(id='resp_040c3ea66128520b006900b11b0d748196979fa5d0de752539', created_at=1761653019.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-mini-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_040c3ea66128520b006900b11ba07c8196bff8fd0b37f5553c', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_040c3ea66128520b006900b121434c8196bc3fc43c870251ea', content=[ResponseOutputText(annotations=[], text='Artificial intelligence is the broad field of building systems that perform tasks requiring human‑like intelligence, and machine learning is a subset of AI that trains algorithms to learn patterns and make predictions from data rather than being explicitly programmed. Machine learning is used in many real‑world applications (recommendations, search, vision, NLP, fraud detection, healthcare, finance, robotics, etc.) but projects commonly stumble on data issues, bias, label noise, leakage, overfitting, poor evaluation, deployment/monitoring problems, and ethical/security concerns. Deep learning — multi‑layer neural networks — is distinctive because it automatically learns hierarchical representations and enables end‑to‑end solutions that scale with data and compute (especially for unstructured data), at the cost of higher data/compute needs, specialized training, and often reduced interpretability and robustness.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id='resp_040c3ea66128520b006900b106292c81969e7a43c2998a29b2', prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='auto', usage=ResponseUsage(input_tokens=4091, input_tokens_details=InputTokensDetails(cached_tokens=2816), output_tokens=492, output_tokens_details=OutputTokensDetails(reasoning_tokens=320), total_tokens=4583), user=None, billing={'payer': 'developer'}, store=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_long_conversation_with_truncation():\n",
    "    \"\"\"\n",
    "    Simulate a conversation with 5 rounds, then demonstrate automatic truncation in action.\n",
    "    Each turn continues from the previous response.\n",
    "    \"\"\"\n",
    "    conversation = [\n",
    "        \"Hi, can you explain what artificial intelligence is?\",\n",
    "        \"How is machine learning different from AI?\",\n",
    "        \"Can you tell me some real-world applications of machine learning?\",\n",
    "        \"What are some challenges or pitfalls in developing ML models?\",\n",
    "        \"How is deep learning unique compared to other machine learning approaches?\"\n",
    "    ]\n",
    "\n",
    "    response_ids = []\n",
    "    previous_id = None\n",
    "\n",
    "    print(\"=== Simulating Long Conversation ===\")\n",
    "    for idx, message in enumerate(conversation):\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-5-mini\",\n",
    "            input=message,\n",
    "            previous_response_id=previous_id,\n",
    "        )\n",
    "        text = response.output[-1].content[0].text\n",
    "        print(f\"Turn {idx+1} Assistant: {text}\\n\")\n",
    "        previous_id = response.id\n",
    "        response_ids.append(previous_id)\n",
    "\n",
    "    # Now ask for a summary, which will likely trigger truncation of the oldest turns\n",
    "    summary_prompt = \"Please summarize everything we've discussed so far in three sentences.\"\n",
    "    truncated_response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=summary_prompt,\n",
    "        previous_response_id=previous_id,\n",
    "        truncation=\"auto\"\n",
    "    )\n",
    "    print(\"=== Truncated Summary Response ===\")\n",
    "    print(truncated_response.output[-1].content[0].text)\n",
    "    return truncated_response\n",
    "\n",
    "# Run the function to demonstrate truncation\n",
    "simulate_long_conversation_with_truncation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o3p4q5r6",
   "metadata": {},
   "source": [
    "## Complete Conversation Example\n",
    "\n",
    "Let's create a complete multi-turn conversation with state management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "p4q5r6s7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting a multi-turn conversation\n",
      "============================================================\n",
      "\n",
      "Turn 1 - Response ID: resp_08c771d947e40fae006900b17c2d188196bd5b4a287252ef9b\n",
      "Assistant: Welcome to the world of Python! Here’s a structured approach to get you started:\n",
      "\n",
      "### 1. **Basic Syntax**\n",
      "   - **Variables**: Learn how to create and use variables.\n",
      "   - **Data Types**: Understand integers, floats, strings, and booleans.\n",
      "   - **Comments**: How to write comments in your code.\n",
      "\n",
      "### 2. **Control Structures**\n",
      "   - **Conditional Statements**: Learn about `if`, `elif`, and `else` statements.\n",
      "   - **Loops**: Understand `for` loops and `while` loops.\n",
      "\n",
      "### 3. **Data Structures**\n",
      "   - **Lists**: Learn how to create and manipulate lists.\n",
      "   - **Tuples**: Understand immutable sequences.\n",
      "   - **Dictionaries**: Learn about key-value pairs.\n",
      "   - **Sets**: Understand unordered collections of unique elements.\n",
      "\n",
      "### 4. **Functions**\n",
      "   - **Defining Functions**: Learn to write reusable code blocks using `def`.\n",
      "   - **Arguments and Return Values**: Understand how to pass data to functions and return results.\n",
      "\n",
      "### 5. **Modules and Packages**\n",
      "   - **Importing Modules**: Learn how to use built-in modules (like `math` and `random`).\n",
      "   - **Creating Your Own Modules**: Simple practices on how to structure functions across multiple files.\n",
      "\n",
      "### 6. **File Handling**\n",
      "   - **Reading and Writing Files**: Learn to work with text files, reading and writing data.\n",
      "\n",
      "### 7. **Error Handling**\n",
      "   - **Try and Except**: Understand how to handle potential errors in your code.\n",
      "\n",
      "### 8. **Basic Object-Oriented Programming (OOP)**\n",
      "   - **Classes and Objects**: Understand the principles of OOP, including classes, objects, attributes, and methods.\n",
      "\n",
      "### 9. **Basic Libraries**\n",
      "   - **NumPy / Pandas**: For data manipulation (if you're interested in data science).\n",
      "   - **Requests**: For making HTTP requests (if you’re interested in web development).\n",
      "\n",
      "### 10. **Practice**\n",
      "   - **Projects**: Start with simple projects, like a calculator or a to-do list app.\n",
      "   - **Exercises**: Use platforms like LeetCode, HackerRank, or Codecademy for practice.\n",
      "\n",
      "### Additional Resources\n",
      "- **Books**: \"Automate the Boring Stuff with Python\" is highly recommended for beginners.\n",
      "- **Online Courses**: Platforms like Udemy, Coursera, or freeCodeCamp have excellent resources.\n",
      "\n",
      "### Final Tip\n",
      "Start coding as much as you can. The best way to learn is through practice. Don't hesitate to ask questions in forums or engage with community members as you progress.\n",
      "\n",
      "Happy coding!\n",
      "\n",
      "Turn 2 - Response ID: resp_08c771d947e40fae006900b189fa5081968eb2287992c5a0a3\n",
      "Assistant: Certainly! A `for` loop is used to iterate over a sequence (like a list, tuple, string, or range). Here's a simple example that demonstrates how to use a `for` loop to iterate through a list of fruits:\n",
      "\n",
      "```python\n",
      "# List of fruits\n",
      "fruits = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
      "\n",
      "# Using a for loop to iterate through the list\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "```\n",
      "\n",
      "### Output:\n",
      "```\n",
      "apple\n",
      "banana\n",
      "cherry\n",
      "date\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **`fruits`**: This is a list containing several fruit names.\n",
      "- **`for fruit in fruits:`**: This line begins the loop. It says, \"For each item in the list `fruits`, assign it to the variable `fruit`.\"\n",
      "- **`print(fruit)`**: This line prints the current fruit to the console.\n",
      "\n",
      "You can also use a `for` loop to iterate over a range of numbers. Here’s an example:\n",
      "\n",
      "```python\n",
      "# Using a for loop with range\n",
      "for i in range(5):  # This will loop through numbers 0 to 4\n",
      "    print(i)\n",
      "```\n",
      "\n",
      "### Output:\n",
      "```\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- **`range(5)`**: This generates a sequence of numbers from 0 to 4.\n",
      "- The loop runs 5 times, printing each number on a new line.\n",
      "\n",
      "Feel free to modify these examples and practice!\n",
      "\n",
      "Turn 3 - Response ID: resp_08c771d947e40fae006900b191cffc81969abb9fe1a6bec11c\n",
      "Assistant: Great question! Lists and tuples are both used to store collections of items in Python, but they have some key differences:\n",
      "\n",
      "### 1. **Mutability**\n",
      "- **List**: Lists are mutable, meaning you can change, add, or remove items after the list has been created.\n",
      "  ```python\n",
      "  my_list = [1, 2, 3]\n",
      "  my_list[0] = 10  # Change the first item\n",
      "  my_list.append(4)  # Add an item\n",
      "  print(my_list)  # Output: [10, 2, 3, 4]\n",
      "  ```\n",
      "\n",
      "- **Tuple**: Tuples are immutable, meaning once they are created, you cannot change their content. \n",
      "  ```python\n",
      "  my_tuple = (1, 2, 3)\n",
      "  # my_tuple[0] = 10  # This would raise an error\n",
      "  ```\n",
      "\n",
      "### 2. **Syntax**\n",
      "- **List**: Defined using square brackets `[]`.\n",
      "  ```python\n",
      "  my_list = [1, 2, 3]\n",
      "  ```\n",
      "\n",
      "- **Tuple**: Defined using parentheses `()`.\n",
      "  ```python\n",
      "  my_tuple = (1, 2, 3)\n",
      "  ```\n",
      "\n",
      "### 3. **Performance**\n",
      "- **List**: Slightly slower than tuples for iteration and access due to their mutability.\n",
      "- **Tuple**: Generally more memory-efficient and faster to access compared to lists, making them a good choice for fixed collections of items.\n",
      "\n",
      "### 4. **Use Cases**\n",
      "- **List**: Use lists when you need a collection that may change (add, remove, or modify items).\n",
      "- **Tuple**: Use tuples when you need a collection of items that should not change. They're often used for fixed data structures, such as coordinates (x, y), or to return multiple values from a function.\n",
      "\n",
      "### Example:\n",
      "Here's a quick example illustrating the differences:\n",
      "\n",
      "```python\n",
      "# List example\n",
      "my_list = [1, 2, 3]\n",
      "my_list.append(4)  # Modifying the list\n",
      "print(my_list)  # Output: [1, 2, 3, 4]\n",
      "\n",
      "# Tuple example\n",
      "my_tuple = (1, 2, 3)\n",
      "# my_tuple.append(4)  # This would raise an AttributeError\n",
      "print(my_tuple)  # Output: (1, 2, 3)\n",
      "```\n",
      "\n",
      "### Summary\n",
      "- **Mutability**: Lists are mutable, tuples are not.\n",
      "- **Syntax**: Lists use `[]`, tuples use `()`.\n",
      "- **Performance**: Tuples can be more efficient in certain situations.\n",
      "\n",
      "Feel free to ask if you have more questions!\n",
      "\n",
      "Turn 4 (Forked from Turn 1) - Response ID: resp_08c771d947e40fae006900b1a245008196b85ac53b45ef3a6f\n",
      "Assistant: Great choice! Web development with Python can be very rewarding. Here’s a roadmap to help you get started:\n",
      "\n",
      "### 1. **Get Comfortable with Python Basics**\n",
      "   - Before diving into web development, make sure you understand Python fundamentals: syntax, data types, control structures, functions, and data structures.\n",
      "\n",
      "### 2. **Learn HTML, CSS, and JavaScript**\n",
      "   - **HTML**: Understand the structure of web pages.\n",
      "   - **CSS**: Learn how to style your web pages.\n",
      "   - **JavaScript**: Basics of JS for client-side interactivity.\n",
      "\n",
      "### 3. **Choose a Web Framework**\n",
      "   - **Flask**: A lightweight, easy-to-learn framework that's great for beginners.\n",
      "   - **Django**: A more robust framework that includes many built-in features for larger applications.\n",
      "\n",
      "### 4. **Setting Up Your Environment**\n",
      "   - Install Python and set up a virtual environment using `venv` or `conda`.\n",
      "   - Familiarize yourself with package management using `pip`.\n",
      "\n",
      "### 5. **Learn Your Chosen Framework**\n",
      "   - **Flask**:\n",
      "     - Creating Routes: Learn how to define URL endpoints.\n",
      "     - Templates: Use Jinja2 for rendering dynamic HTML.\n",
      "     - Forms: Handling user input via forms.\n",
      "   - **Django**:\n",
      "     - Models and Migrations: Understand how to define your data structure.\n",
      "     - Views and Templates: Learn how to handle requests and render HTML.\n",
      "     - Admin Interface: Leverage Django's built-in admin dashboard.\n",
      "\n",
      "### 6. **Learn About Databases**\n",
      "   - Understand how to connect your application to databases:\n",
      "     - **SQL**: Basic knowledge of SQL (PostgreSQL, SQLite, or MySQL).\n",
      "     - **ORM**: Learn to use an Object-Relational Mapping tool (like SQLAlchemy for Flask or Django ORM).\n",
      "\n",
      "### 7. **Web APIs**\n",
      "   - Understanding RESTful APIs: Learn how to create and consume APIs.\n",
      "   - Use libraries like `requests` to make API calls.\n",
      "\n",
      "### 8. **User Authentication**\n",
      "   - Learn how to implement user registration, login, and authentication.\n",
      "   - Understand sessions and cookies for state management.\n",
      "\n",
      "### 9. **Deploy Your Application**\n",
      "   - Learn how to deploy your app on platforms like Heroku, Vercel, or DigitalOcean.\n",
      "   - Basic knowledge of Docker can be beneficial.\n",
      "\n",
      "### 10. **Practice and Build Projects**\n",
      "   - Start with small web projects:\n",
      "     - A personal blog.\n",
      "     - A simple CRUD application (like a task manager).\n",
      "   - Gradually move to more complex projects.\n",
      "\n",
      "### Additional Resources\n",
      "- **Online Tutorials**: Check out resources like Flask or Django documentation, or courses on platforms like Udemy and Coursera.\n",
      "- **Books**: “Flask Web Development” or “Django for Beginners”.\n",
      "\n",
      "### Join the Community\n",
      "Engage with other developers through forums, meetups, or social media. Platforms like Stack Overflow and Reddit can be great for getting help.\n",
      "\n",
      "### Final Tip\n",
      "Focus on building projects that interest you. Practical experience is the best way to solidify your understanding and skills.\n",
      "\n",
      "Happy coding in web development! 🚀\n",
      "\n",
      "============================================================\n",
      "Conversation complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def multi_turn_conversation():\n",
    "    \"\"\"Demonstrate a complete multi-turn conversation.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Starting a multi-turn conversation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Turn 1: Initial response\n",
    "    response_1 = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        instructions=\"You are a helpful Python programming tutor.\",\n",
    "        input=\"I'm new to Python. What should I learn first?\"\n",
    "    )\n",
    "    print(f\"\\nTurn 1 - Response ID: {response_1.id}\")\n",
    "    print(f\"Assistant: {response_1.output[0].content[0].text}\\n\")\n",
    "    \n",
    "    # Turn 2: Continue conversation\n",
    "    response_2 = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=\"Can you give me an example of a for loop?\",\n",
    "        previous_response_id=response_1.id\n",
    "    )\n",
    "    print(f\"Turn 2 - Response ID: {response_2.id}\")\n",
    "    print(f\"Assistant: {response_2.output[0].content[0].text}\\n\")\n",
    "    \n",
    "    # Turn 3: Continue further\n",
    "    response_3 = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=\"What's the difference between a list and a tuple?\",\n",
    "        previous_response_id=response_2.id\n",
    "    )\n",
    "    print(f\"Turn 3 - Response ID: {response_3.id}\")\n",
    "    print(f\"Assistant: {response_3.output[0].content[0].text}\\n\")\n",
    "    \n",
    "    # Turn 4: Fork back to turn 1\n",
    "    response_4 = client.responses.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        input=\"Actually, what about web development with Python instead?\",\n",
    "        previous_response_id=response_1.id  # Fork from first response\n",
    "    )\n",
    "    print(f\"Turn 4 (Forked from Turn 1) - Response ID: {response_4.id}\")\n",
    "    print(f\"Assistant: {response_4.output[0].content[0].text}\\n\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Conversation complete\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return response_1, response_2, response_3, response_4\n",
    "\n",
    "# Run the complete conversation example\n",
    "conv_responses = multi_turn_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5r6s7t8",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Conversation Management\n",
    "\n",
    "- **Store response IDs**: Keep track of response IDs to continue conversations\n",
    "- **Use forking wisely**: Fork conversations to explore alternative paths without losing context\n",
    "- **Monitor token usage**: Remember that all prior tokens are billable when using `previous_response_id`\n",
    "- **Set storage preferences**: Use `store=False` for sensitive conversations\n",
    "\n",
    "### 2. Performance Optimization\n",
    "\n",
    "- **Use appropriate models**: Use `gpt-4o-mini` for simple tasks, `gpt-4o` for complex reasoning\n",
    "- **Limit context**: Use `max_prompt_tokens` and `truncation=\"auto\"` for long conversations\n",
    "- **Cache responses**: Store frequently accessed responses locally to reduce API calls\n",
    "\n",
    "### 3. Content Best Practices\n",
    "\n",
    "- **Clear instructions**: Provide clear, specific instructions for consistent behavior\n",
    "- **Structured input**: Use role-based messages for complex conversations\n",
    "- **Tool selection**: Choose appropriate tools (web_search, file_search, code_interpreter) based on the task\n",
    "\n",
    "### 4. Error Handling\n",
    "\n",
    "Always implement proper error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "r6s7t8u9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_create_response(user_input, previous_response_id=None):\n",
    "    \"\"\"Create a response with proper error handling.\"\"\"\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=user_input,\n",
    "            previous_response_id=previous_response_id\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating response: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example with error handling\n",
    "safe_response = safe_create_response(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s7t8u9v0",
   "metadata": {},
   "source": [
    "## Exercise: Build a Conversational Assistant\n",
    "\n",
    "Try this exercise to practice working with conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "t8u9v0w1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactive conversation. Type 'quit' to exit.\n",
      "\n",
      "===========User Input===========\n",
      "HI!\n",
      "================================\n",
      "=======Assistant Response=======\n",
      "Hi there! How can I help you today?\n",
      "================================\n",
      "===========User Input===========\n",
      "YOu can tell me what is the meaning of life in one sentence.\n",
      "================================\n",
      "=======Assistant Response=======\n",
      "The meaning of life is to create and pursue purpose, connection, and joy by growing, loving, and contributing to something larger than yourself.\n",
      "================================\n",
      "===========User Input===========\n",
      "quit\n",
      "================================\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def interactive_conversation():\n",
    "    \"\"\"\n",
    "    Create an interactive conversation loop.\n",
    "    Type 'quit' to exit.\n",
    "    \"\"\"\n",
    "    print(\"Starting interactive conversation. Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    last_response_id = None\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        print(\"===========User Input===========\")\n",
    "        print(user_input)\n",
    "        print(\"================================\")\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-5-mini\",\n",
    "                instructions=\"You are a friendly and helpful assistant.\",\n",
    "                input=user_input,\n",
    "                previous_response_id=last_response_id\n",
    "            )\n",
    "            \n",
    "            last_response_id = response.id\n",
    "            print(\"=======Assistant Response=======\")   \n",
    "            print(response.output[-1].content[0].text)\n",
    "            print(\"================================\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\\n\")\n",
    "\n",
    "# Uncomment to run the interactive conversation\n",
    "interactive_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u9v0w1x2",
   "metadata": {},
   "source": [
    "## Migration from Assistants API\n",
    "\n",
    "If you're migrating from the Assistants API, here's a quick reference:\n",
    "\n",
    "### Assistants API Pattern\n",
    "```python\n",
    "# Old way (Assistants API)\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"My Assistant\",\n",
    "    instructions=\"You are helpful.\",\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Hello\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "```\n",
    "\n",
    "### Responses API Pattern\n",
    "```python\n",
    "# New way (Responses API)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are helpful.\",\n",
    "    input=\"Hello\"\n",
    ")\n",
    "\n",
    "# Continue conversation\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"How are you?\",\n",
    "    previous_response_id=response.id\n",
    ")\n",
    "```\n",
    "\n",
    "**Benefits of Migration:**\n",
    "- Simpler API with less boilerplate\n",
    "- Faster response times\n",
    "- Built-in state management\n",
    "- Conversation forking capabilities\n",
    "- Unified interface for tools and multimodal inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v0w1x2y3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Responses API provides a streamlined, powerful way to build conversational AI applications. Key takeaways:\n",
    "\n",
    "1. **Simplified State Management**: No need to manually manage threads and messages\n",
    "2. **Server-Side Storage**: Conversations are stored automatically for 30 days\n",
    "3. **Flexible Continuation**: Use `previous_response_id` to continue or fork conversations\n",
    "4. **Built-in Tools**: Web search, file search, and code interpreter available out of the box\n",
    "5. **Multimodal Support**: Handle text, images, and files in the same API\n",
    "6. **Cost Management**: Control token usage with limits and truncation\n",
    "\n",
    "The Responses API represents a significant improvement over the Assistants API, offering better performance, simpler code, and more powerful features for building modern AI applications.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [OpenAI Responses API Documentation](https://platform.openai.com/docs/api-reference/responses)\n",
    "- [OpenAI Cookbook - Responses API Examples](https://cookbook.openai.com/examples/responses_api/responses_example)\n",
    "- [Migration Guide: Assistants API to Responses API](https://apimagic.ai/blog/switching-assistant-responses-api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
