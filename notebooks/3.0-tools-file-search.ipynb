{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5885d562",
   "metadata": {},
   "source": [
    "# Building a Smart Knowledge Base with OpenAI Assistants File Search\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we'll learn how to use the File Search capability of OpenAI's Assistants API to create a smart knowledge base system. We'll build a customer support assistant that can answer questions about product documentation, user guides, and FAQs.\n",
    "\n",
    "File Search allows Assistants to access knowledge from documents provided by you or your users. OpenAI automatically handles:\n",
    "- Parsing and chunking documents\n",
    "- Creating and storing embeddings\n",
    "- Performing vector and keyword search\n",
    "- Retrieving relevant content to answer queries\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's set up our environment with the required imports and initialize our OpenAI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acc07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae86af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# Create a helper function to print responses nicely\n",
    "def print_response(message):\n",
    "    if hasattr(message.content[0], 'text'):\n",
    "        print(f\"{message.role}: {message.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827566d",
   "metadata": {},
   "source": [
    "## Creating the Knowledge Base Assistant\n",
    "\n",
    "Let's create an assistant specifically designed to handle product documentation queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995e7ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created assistant with ID: asst_JdEjTHdrxGRTHSopdn8F8uxM\n"
     ]
    }
   ],
   "source": [
    "# Create the assistant with file search enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Product Support Assistant\",\n",
    "    instructions=\"\"\"You are a helpful product support assistant. \n",
    "    Use the provided documentation to answer customer questions accurately.\n",
    "    If you're not sure about something, admit it and stick to the information in the documents.\"\"\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}]\n",
    ")\n",
    "\n",
    "print(f\"Created assistant with ID: {assistant.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f3931",
   "metadata": {},
   "source": [
    "## Setting Up the Vector Store\n",
    "\n",
    "The File Search tool uses Vector Store objects to manage and search through your documents. Let's create one for our product documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d47ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector store with ID: vs_68752c0f952481918ba7105fb2ea5c28\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store for our documentation\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "    name=\"Product Documentation\"\n",
    ")\n",
    "\n",
    "print(f\"Created vector store with ID: {vector_store.id}\")\n",
    "\n",
    "# Update the assistant to use our vector store\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tool_resources={\n",
    "        \"file_search\": {\n",
    "            \"vector_store_ids\": [vector_store.id]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3311b",
   "metadata": {},
   "source": [
    "## Adding Documentation Files\n",
    "\n",
    "Now let's create a function to add files to our vector store. We'll use the upload_and_poll helper to ensure files are processed completely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6250be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_files_to_vector_store(file_paths, vector_store_id):\n",
    "    \"\"\"\n",
    "    Upload files to the vector store and wait for processing to complete\n",
    "    \"\"\"\n",
    "    # Prepare the files for upload\n",
    "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "    \n",
    "    try:\n",
    "        # Upload files and wait for processing\n",
    "        file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "            vector_store_id=vector_store_id,\n",
    "            files=file_streams\n",
    "        )\n",
    "        \n",
    "        print(f\"Upload status: {file_batch.status}\")\n",
    "        print(f\"File counts: {file_batch.file_counts}\")\n",
    "        return file_batch\n",
    "        \n",
    "    finally:\n",
    "        # Clean up file streams\n",
    "        for stream in file_streams:\n",
    "            stream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799f037",
   "metadata": {},
   "source": [
    "## Creating a Thread Manager\n",
    "\n",
    "Let's create a class to manage our customer support threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aafedaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportThreadManager:\n",
    "    def __init__(self, assistant_id):\n",
    "        self.client = OpenAI()\n",
    "        self.assistant_id = assistant_id\n",
    "        \n",
    "    def create_thread(self):\n",
    "        \"\"\"Create a new support thread\"\"\"\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        return self.thread\n",
    "    \n",
    "    def add_message(self, content, file_id=None):\n",
    "        \"\"\"Add a message to the thread\"\"\"\n",
    "        message_params = {\n",
    "            \"thread_id\": self.thread.id,\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }\n",
    "        \n",
    "        if file_id:\n",
    "            message_params[\"attachments\"] = [{\n",
    "                \"file_id\": file_id,\n",
    "                \"tools\": [{\"type\": \"file_search\"}]\n",
    "            }]\n",
    "            \n",
    "        return self.client.beta.threads.messages.create(**message_params)\n",
    "    \n",
    "    def process_annotations(self, message):\n",
    "        \"\"\"Process message annotations to format citations\"\"\"\n",
    "        if not message.content or not message.content[0].text:\n",
    "            return \"No text content found\"\n",
    "        \n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        \n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, \n",
    "                f' [{index}]'\n",
    "            )\n",
    "            \n",
    "            if hasattr(annotation, 'file_citation'):\n",
    "                cited_file = self.client.files.retrieve(annotation.file_citation.file_id)\n",
    "                citations.append(\n",
    "                    f'[{index}] {annotation.file_citation.quote} from {cited_file.filename}'\n",
    "                )\n",
    "                \n",
    "        final_content = message_content.value\n",
    "        if citations:\n",
    "            final_content += '\\n\\nSources:\\n' + '\\n'.join(citations)\n",
    "            \n",
    "        return final_content\n",
    "    \n",
    "    def get_response(self, event_handler=None):\n",
    "        \"\"\"Run the assistant and get a response\"\"\"\n",
    "        with self.client.beta.threads.runs.stream(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant_id,\n",
    "            event_handler=event_handler,\n",
    "        ) as stream:\n",
    "            stream.until_done()\n",
    "            \n",
    "        # Get the latest message\n",
    "        messages = self.client.beta.threads.messages.list(\n",
    "            thread_id=self.thread.id,\n",
    "            order=\"desc\",\n",
    "            limit=1\n",
    "        )\n",
    "        \n",
    "        latest_message = messages.data[0]\n",
    "        return self.process_annotations(latest_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77eeb89",
   "metadata": {},
   "source": [
    "## Creating an Event Handler\n",
    "\n",
    "To handle streaming responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146f0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportEventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "    \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "    \n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nsearching documentation...\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11dfcd",
   "metadata": {},
   "source": [
    "## Putting It All Together\n",
    "\n",
    "Let's create a complete example of using our support system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a0350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "searching documentation...\n",
      "\n",
      "\n",
      "assistant > It seems the document you uploaded does not contain specific instructions on how to reset your password. If you're trying to reset your password for a particular service or platform, typically, you would go to the login page and select an option like \"Forgot Password?\" or \"Reset Password\" and follow the instructions provided. If you have a specific service in mind, let me know so I can provide more tailored guidance!\n",
      "Formatted Response:\n",
      "It seems the document you uploaded does not contain specific instructions on how to reset your password. If you're trying to reset your password for a particular service or platform, typically, you would go to the login page and select an option like \"Forgot Password?\" or \"Reset Password\" and follow the instructions provided. If you have a specific service in mind, let me know so I can provide more tailored guidance!\n"
     ]
    }
   ],
   "source": [
    "# Initialize our support thread manager\n",
    "support_manager = SupportThreadManager(assistant.id)\n",
    "\n",
    "# Create a new thread\n",
    "thread = support_manager.create_thread()\n",
    "\n",
    "# Example customer query\n",
    "query = \"How do I reset my password?\"\n",
    "support_manager.add_message(query)\n",
    "\n",
    "# Get and print the response\n",
    "response = support_manager.get_response(SupportEventHandler())\n",
    "print(\"\\nFormatted Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9586c",
   "metadata": {},
   "source": [
    "## Additional Features: Thread-Specific Documents\n",
    "\n",
    "Sometimes customers might provide additional context in the form of documents. Here's how to handle that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8e3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_customer_attachment(file_path, thread_manager):\n",
    "    \"\"\"Handle a customer-provided document\"\"\"\n",
    "    # Upload the file\n",
    "    file = client.files.create(\n",
    "        file=open(file_path, \"rb\"),\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "    \n",
    "    # Add message with attachment\n",
    "    thread_manager.add_message(\n",
    "        \"Please refer to the attached document for context.\",\n",
    "        file_id=file.id\n",
    "    )\n",
    "    \n",
    "    return file.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae529e",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "1. **Document Preparation**:\n",
    "   - Keep documents under 512 MB\n",
    "   - Use supported file formats (PDF, DOCX, TXT, etc.)\n",
    "   - Structure documents clearly with headers and sections\n",
    "\n",
    "2. **Vector Store Management**:\n",
    "   - Create separate vector stores for different types of documentation\n",
    "   - Monitor the status of file processing before running queries\n",
    "   - Clean up or archive outdated documentation\n",
    "\n",
    "3. **Query Handling**:\n",
    "   - Be specific in the assistant's instructions\n",
    "   - Process and display citations properly\n",
    "   - Handle errors gracefully\n",
    "\n",
    "## Clean Up Function\n",
    "\n",
    "Here's a utility function to clean up resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113be6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_resources(vector_store_id=None, file_ids=None):\n",
    "    \"\"\"Clean up vector stores and files when no longer needed\"\"\"\n",
    "    if vector_store_id:\n",
    "        try:\n",
    "            client.beta.vector_stores.delete(vector_store_id)\n",
    "            print(f\"Deleted vector store: {vector_store_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting vector store: {e}\")\n",
    "    \n",
    "    if file_ids:\n",
    "        for file_id in file_ids:\n",
    "            try:\n",
    "                client.files.delete(file_id)\n",
    "                print(f\"Deleted file: {file_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a5abf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've built a comprehensive support system using OpenAI's Assistants API with File Search. The system can:\n",
    "- Manage documentation in vector stores\n",
    "- Handle customer queries with context from documentation\n",
    "- Process customer-provided documents\n",
    "- Provide cited responses from the knowledge base\n",
    "\n",
    "Try experimenting with different types of documentation and queries to see how the system performs in various scenarios. Remember to handle your API keys securely and manage your resources efficiently in production environments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
