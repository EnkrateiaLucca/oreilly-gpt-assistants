{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatKit + OpenAI Responses API Integration\n",
    "\n",
    "This notebook demonstrates how to integrate OpenAI's ChatKit UI library with the Responses API to build a modern chat interface.\n",
    "\n",
    "## What is ChatKit?\n",
    "\n",
    "ChatKit is OpenAI's framework-agnostic, drop-in chat solution for building high-quality, AI-powered chat experiences. It provides:\n",
    "\n",
    "- üé® **Polished UI Components** - Ready-to-use chat interface\n",
    "- üîÑ **Streaming Support** - Real-time response streaming\n",
    "- üõ†Ô∏è **Tool Integration** - Support for function calling and widgets\n",
    "- üìé **Attachments** - File and image upload handling\n",
    "- üéØ **Framework Agnostic** - Works with React, Vue, Angular, or vanilla JS\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  React Frontend ‚îÇ\n",
    "‚îÇ   (ChatKit UI)  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚îÇ /api/chatkit/session\n",
    "         ‚îÇ /api/chat\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ FastAPI Backend ‚îÇ\n",
    "‚îÇ (Python Server) ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚îÇ Responses API\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  OpenAI API     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Setup Requirements\n",
    "\n",
    "### Backend (Python)\n",
    "```bash\n",
    "pip install fastapi uvicorn openai python-dotenv\n",
    "```\n",
    "\n",
    "### Frontend (Node.js)\n",
    "```bash\n",
    "npm install @openai/chatkit-react react react-dom\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Backend Implementation with Responses API\n",
    "\n",
    "Let's create a FastAPI backend that uses the OpenAI Responses API to handle chat messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend Code: `backend/app.py`\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "app = FastAPI()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Enable CORS for frontend\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# In-memory storage for conversation history\n",
    "conversations: Dict[str, List[Dict]] = {}\n",
    "\n",
    "\n",
    "class ChatKitSessionRequest(BaseModel):\n",
    "    \"\"\"Request model for creating a ChatKit session\"\"\"\n",
    "    existing_session_id: Optional[str] = None\n",
    "\n",
    "\n",
    "class ChatKitSessionResponse(BaseModel):\n",
    "    \"\"\"Response model for ChatKit session\"\"\"\n",
    "    client_secret: str\n",
    "    session_id: str\n",
    "\n",
    "\n",
    "class ChatMessage(BaseModel):\n",
    "    \"\"\"Chat message model\"\"\"\n",
    "    role: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    \"\"\"Request model for chat endpoint\"\"\"\n",
    "    session_id: str\n",
    "    message: str\n",
    "    messages: Optional[List[ChatMessage]] = None\n",
    "\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    \"\"\"Response model for chat endpoint\"\"\"\n",
    "    response: str\n",
    "    session_id: str\n",
    "\n",
    "\n",
    "@app.post(\"/api/chatkit/session\")\n",
    "async def create_chatkit_session(\n",
    "    request: Optional[ChatKitSessionRequest] = None\n",
    ") -> ChatKitSessionResponse:\n",
    "    \"\"\"\n",
    "    Create or retrieve a ChatKit session.\n",
    "    \n",
    "    ChatKit requires a client_secret for authentication. In a production app,\n",
    "    this would be a secure token. For this demo, we use the session_id.\n",
    "    \"\"\"\n",
    "    session_id = request.existing_session_id if request else None\n",
    "    \n",
    "    if not session_id:\n",
    "        # Create new session\n",
    "        session_id = str(uuid.uuid4())\n",
    "        conversations[session_id] = []\n",
    "    \n",
    "    # In production, generate a secure token here\n",
    "    # For demo purposes, we'll use the session_id as the client_secret\n",
    "    client_secret = f\"demo_secret_{session_id}\"\n",
    "    \n",
    "    return ChatKitSessionResponse(\n",
    "        client_secret=client_secret,\n",
    "        session_id=session_id\n",
    "    )\n",
    "\n",
    "\n",
    "@app.post(\"/api/chat\")\n",
    "async def chat(request: ChatRequest) -> ChatResponse:\n",
    "    \"\"\"\n",
    "    Handle chat messages using OpenAI's Responses API.\n",
    "    \n",
    "    This endpoint:\n",
    "    1. Retrieves or creates conversation history\n",
    "    2. Adds the user's message to history\n",
    "    3. Calls OpenAI's Responses API\n",
    "    4. Stores the assistant's response\n",
    "    5. Returns the response to the frontend\n",
    "    \"\"\"\n",
    "    session_id = request.session_id\n",
    "    \n",
    "    # Get or create conversation history\n",
    "    if session_id not in conversations:\n",
    "        conversations[session_id] = []\n",
    "    \n",
    "    # Add user message to history\n",
    "    conversations[session_id].append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": request.message\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        # Call OpenAI Responses API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=conversations[session_id],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Extract assistant's response\n",
    "        assistant_message = response.choices[0].message.content\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        conversations[session_id].append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_message\n",
    "        })\n",
    "        \n",
    "        return ChatResponse(\n",
    "            response=assistant_message,\n",
    "            session_id=session_id\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "\n",
    "@app.get(\"/api/conversations/{session_id}\")\n",
    "async def get_conversation(session_id: str):\n",
    "    \"\"\"\n",
    "    Retrieve conversation history for a session.\n",
    "    Useful for debugging or resuming conversations.\n",
    "    \"\"\"\n",
    "    if session_id not in conversations:\n",
    "        raise HTTPException(status_code=404, detail=\"Session not found\")\n",
    "    \n",
    "    return {\"session_id\": session_id, \"messages\": conversations[session_id]}\n",
    "\n",
    "\n",
    "@app.delete(\"/api/conversations/{session_id}\")\n",
    "async def delete_conversation(session_id: str):\n",
    "    \"\"\"\n",
    "    Clear conversation history for a session.\n",
    "    \"\"\"\n",
    "    if session_id in conversations:\n",
    "        del conversations[session_id]\n",
    "        return {\"message\": \"Conversation deleted\"}\n",
    "    \n",
    "    raise HTTPException(status_code=404, detail=\"Session not found\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Frontend Implementation with ChatKit\n",
    "\n",
    "Now let's create a React frontend using ChatKit components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontend Code: `frontend/src/App.jsx`\n",
    "\n",
    "```jsx\n",
    "import React, { useState } from 'react';\n",
    "import { ChatKit, useChatKit } from '@openai/chatkit-react';\n",
    "import '@openai/chatkit-react/styles.css';\n",
    "\n",
    "function App() {\n",
    "  const [sessionId, setSessionId] = useState(null);\n",
    "  \n",
    "  const { control } = useChatKit({\n",
    "    api: {\n",
    "      // Get client secret from backend\n",
    "      async getClientSecret(existingSessionId) {\n",
    "        const response = await fetch('http://localhost:8000/api/chatkit/session', {\n",
    "          method: 'POST',\n",
    "          headers: {\n",
    "            'Content-Type': 'application/json',\n",
    "          },\n",
    "          body: JSON.stringify({\n",
    "            existing_session_id: existingSessionId,\n",
    "          }),\n",
    "        });\n",
    "        \n",
    "        const data = await response.json();\n",
    "        setSessionId(data.session_id);\n",
    "        return data.client_secret;\n",
    "      },\n",
    "      \n",
    "      // Send messages to backend\n",
    "      async sendMessage(message) {\n",
    "        if (!sessionId) {\n",
    "          throw new Error('No session ID available');\n",
    "        }\n",
    "        \n",
    "        const response = await fetch('http://localhost:8000/api/chat', {\n",
    "          method: 'POST',\n",
    "          headers: {\n",
    "            'Content-Type': 'application/json',\n",
    "          },\n",
    "          body: JSON.stringify({\n",
    "            session_id: sessionId,\n",
    "            message: message.content,\n",
    "          }),\n",
    "        });\n",
    "        \n",
    "        const data = await response.json();\n",
    "        \n",
    "        // Return in ChatKit expected format\n",
    "        return {\n",
    "          role: 'assistant',\n",
    "          content: data.response,\n",
    "        };\n",
    "      },\n",
    "    },\n",
    "    \n",
    "    // Optional configuration\n",
    "    config: {\n",
    "      model: 'gpt-4o-mini',\n",
    "      welcomeMessage: 'Hello! How can I help you today?',\n",
    "    },\n",
    "  });\n",
    "\n",
    "  return (\n",
    "    <div className=\"App\" style={{\n",
    "      display: 'flex',\n",
    "      justifyContent: 'center',\n",
    "      alignItems: 'center',\n",
    "      height: '100vh',\n",
    "      backgroundColor: '#f5f5f5',\n",
    "      padding: '20px',\n",
    "    }}>\n",
    "      <div style={{\n",
    "        width: '100%',\n",
    "        maxWidth: '800px',\n",
    "        height: '600px',\n",
    "        boxShadow: '0 4px 6px rgba(0, 0, 0, 0.1)',\n",
    "        borderRadius: '12px',\n",
    "        overflow: 'hidden',\n",
    "      }}>\n",
    "        <ChatKit \n",
    "          control={control} \n",
    "          style={{ height: '100%', width: '100%' }}\n",
    "        />\n",
    "      </div>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Simple HTML/Vanilla JS Implementation\n",
    "\n",
    "If you prefer not to use React, here's a vanilla JavaScript version:\n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "  <title>ChatKit + Responses API Demo</title>\n",
    "  <script src=\"https://cdn.platform.openai.com/deployments/chatkit/chatkit.js\" async></script>\n",
    "  <style>\n",
    "    body {\n",
    "      margin: 0;\n",
    "      padding: 20px;\n",
    "      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;\n",
    "      background: #f5f5f5;\n",
    "      display: flex;\n",
    "      justify-content: center;\n",
    "      align-items: center;\n",
    "      min-height: 100vh;\n",
    "    }\n",
    "    #chat-container {\n",
    "      width: 100%;\n",
    "      max-width: 800px;\n",
    "      height: 600px;\n",
    "      background: white;\n",
    "      border-radius: 12px;\n",
    "      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <div id=\"chat-container\"></div>\n",
    "\n",
    "  <script>\n",
    "    let sessionId = null;\n",
    "    \n",
    "    // Initialize ChatKit when the library loads\n",
    "    window.addEventListener('load', async () => {\n",
    "      if (!window.ChatKit) {\n",
    "        console.error('ChatKit library not loaded');\n",
    "        return;\n",
    "      }\n",
    "      \n",
    "      const chatKit = new window.ChatKit({\n",
    "        container: document.getElementById('chat-container'),\n",
    "        \n",
    "        api: {\n",
    "          async getClientSecret(existingSessionId) {\n",
    "            const response = await fetch('http://localhost:8000/api/chatkit/session', {\n",
    "              method: 'POST',\n",
    "              headers: { 'Content-Type': 'application/json' },\n",
    "              body: JSON.stringify({ existing_session_id: existingSessionId }),\n",
    "            });\n",
    "            \n",
    "            const data = await response.json();\n",
    "            sessionId = data.session_id;\n",
    "            return data.client_secret;\n",
    "          },\n",
    "          \n",
    "          async sendMessage(message) {\n",
    "            if (!sessionId) {\n",
    "              throw new Error('No session ID available');\n",
    "            }\n",
    "            \n",
    "            const response = await fetch('http://localhost:8000/api/chat', {\n",
    "              method: 'POST',\n",
    "              headers: { 'Content-Type': 'application/json' },\n",
    "              body: JSON.stringify({\n",
    "                session_id: sessionId,\n",
    "                message: message.content,\n",
    "              }),\n",
    "            });\n",
    "            \n",
    "            const data = await response.json();\n",
    "            return {\n",
    "              role: 'assistant',\n",
    "              content: data.response,\n",
    "            };\n",
    "          },\n",
    "        },\n",
    "        \n",
    "        config: {\n",
    "          welcomeMessage: 'Hello! How can I help you today?',\n",
    "        },\n",
    "      });\n",
    "    });\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Running the Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Start the Backend\n",
    "\n",
    "Create a `.env` file in the backend directory:\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "```\n",
    "\n",
    "Run the FastAPI server:\n",
    "```bash\n",
    "cd backend\n",
    "python app.py\n",
    "```\n",
    "\n",
    "The backend will start at `http://localhost:8000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start the Frontend\n",
    "\n",
    "#### For React Version:\n",
    "```bash\n",
    "cd frontend\n",
    "npm install\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "#### For HTML Version:\n",
    "Simply open the HTML file in your browser or use a simple HTTP server:\n",
    "```bash\n",
    "python -m http.server 3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing the Integration\n",
    "\n",
    "Let's write a simple test to verify our backend is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Base URL for the API\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "def test_chatkit_integration():\n",
    "    \"\"\"Test the ChatKit + Responses API integration\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing ChatKit Integration...\\n\")\n",
    "    \n",
    "    # Step 1: Create a session\n",
    "    print(\"1Ô∏è‚É£ Creating session...\")\n",
    "    session_response = requests.post(f\"{BASE_URL}/api/chatkit/session\")\n",
    "    session_data = session_response.json()\n",
    "    session_id = session_data[\"session_id\"]\n",
    "    print(f\"   ‚úÖ Session created: {session_id}\\n\")\n",
    "    \n",
    "    # Step 2: Send a message\n",
    "    print(\"2Ô∏è‚É£ Sending message...\")\n",
    "    chat_request = {\n",
    "        \"session_id\": session_id,\n",
    "        \"message\": \"Hello! What is OpenAI's Responses API?\"\n",
    "    }\n",
    "    chat_response = requests.post(\n",
    "        f\"{BASE_URL}/api/chat\",\n",
    "        json=chat_request\n",
    "    )\n",
    "    chat_data = chat_response.json()\n",
    "    print(f\"   üì§ User: {chat_request['message']}\")\n",
    "    print(f\"   üì• Assistant: {chat_data['response'][:100]}...\\n\")\n",
    "    \n",
    "    # Step 3: Get conversation history\n",
    "    print(\"3Ô∏è‚É£ Retrieving conversation history...\")\n",
    "    history_response = requests.get(\n",
    "        f\"{BASE_URL}/api/conversations/{session_id}\"\n",
    "    )\n",
    "    history_data = history_response.json()\n",
    "    print(f\"   ‚úÖ Messages in conversation: {len(history_data['messages'])}\\n\")\n",
    "    \n",
    "    # Step 4: Send a follow-up message\n",
    "    print(\"4Ô∏è‚É£ Sending follow-up message...\")\n",
    "    followup_request = {\n",
    "        \"session_id\": session_id,\n",
    "        \"message\": \"Can you give me a specific example?\"\n",
    "    }\n",
    "    followup_response = requests.post(\n",
    "        f\"{BASE_URL}/api/chat\",\n",
    "        json=followup_request\n",
    "    )\n",
    "    followup_data = followup_response.json()\n",
    "    print(f\"   üì§ User: {followup_request['message']}\")\n",
    "    print(f\"   üì• Assistant: {followup_data['response'][:100]}...\\n\")\n",
    "    \n",
    "    print(\"‚úÖ All tests passed!\")\n",
    "\n",
    "# Uncomment to run the test\n",
    "# test_chatkit_integration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Features Demonstrated\n",
    "\n",
    "### 1. **Session Management**\n",
    "- Each user gets a unique session ID\n",
    "- Conversations are stored in memory (can be persisted to database)\n",
    "- Session IDs enable resuming conversations\n",
    "\n",
    "### 2. **Conversation History**\n",
    "- Messages are stored and passed to the Responses API\n",
    "- Enables context-aware responses\n",
    "- Can retrieve or delete conversation history via API endpoints\n",
    "\n",
    "### 3. **OpenAI Responses API Integration**\n",
    "- Uses `client.chat.completions.create()` instead of Assistants API\n",
    "- Direct API calls with conversation history\n",
    "- Simpler architecture compared to Assistants API\n",
    "\n",
    "### 4. **ChatKit UI**\n",
    "- Professional chat interface out of the box\n",
    "- Handles message rendering and input\n",
    "- Responsive design and mobile-friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features to Add\n",
    "\n",
    "### 1. **Streaming Responses**\n",
    "\n",
    "Modify the backend to support streaming:\n",
    "\n",
    "```python\n",
    "from fastapi.responses import StreamingResponse\n",
    "\n",
    "@app.post(\"/api/chat/stream\")\n",
    "async def chat_stream(request: ChatRequest):\n",
    "    async def generate():\n",
    "        stream = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=conversations[request.session_id],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                yield f\"data: {json.dumps({'content': chunk.choices[0].delta.content})}\\n\\n\"\n",
    "    \n",
    "    return StreamingResponse(generate(), media_type=\"text/event-stream\")\n",
    "```\n",
    "\n",
    "### 2. **Function Calling**\n",
    "\n",
    "Add tools to the Responses API:\n",
    "\n",
    "```python\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=conversations[session_id],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. **Persistent Storage**\n",
    "\n",
    "Replace in-memory storage with a database:\n",
    "\n",
    "```python\n",
    "from sqlalchemy import create_engine, Column, String, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Conversation(Base):\n",
    "    __tablename__ = \"conversations\"\n",
    "    session_id = Column(String, primary_key=True)\n",
    "    messages = Column(JSON)\n",
    "```\n",
    "\n",
    "### 4. **Authentication**\n",
    "\n",
    "Add user authentication:\n",
    "\n",
    "```python\n",
    "from fastapi.security import HTTPBearer\n",
    "\n",
    "security = HTTPBearer()\n",
    "\n",
    "@app.post(\"/api/chat\")\n",
    "async def chat(request: ChatRequest, credentials: HTTPAuthorizationCredentials = Depends(security)):\n",
    "    # Verify token\n",
    "    user_id = verify_token(credentials.credentials)\n",
    "    # ... rest of the code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Responses API vs Assistants API\n",
    "\n",
    "| Feature | Responses API (This Example) | Assistants API |\n",
    "|---------|----------------------------|----------------|\n",
    "| **Complexity** | Simple, direct API calls | More complex, thread-based |\n",
    "| **State Management** | You manage conversation history | OpenAI manages threads |\n",
    "| **Built-in Tools** | Manual implementation | Code interpreter, file search |\n",
    "| **Cost** | Pay per token | Pay per token + storage |\n",
    "| **Control** | Full control over flow | Less control, more automation |\n",
    "| **Best For** | Simple chatbots, quick prototypes | Complex agents, file operations |\n",
    "\n",
    "### When to Use Responses API:\n",
    "- ‚úÖ Simple chat applications\n",
    "- ‚úÖ Full control over conversation flow\n",
    "- ‚úÖ Custom state management\n",
    "- ‚úÖ Lower complexity\n",
    "\n",
    "### When to Use Assistants API:\n",
    "- ‚úÖ Need built-in tools (code interpreter, file search)\n",
    "- ‚úÖ Long-running conversations\n",
    "- ‚úÖ File operations and analysis\n",
    "- ‚úÖ OpenAI manages state for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Deploy to Production**\n",
    "   - Use a production ASGI server (gunicorn + uvicorn)\n",
    "   - Add proper authentication and rate limiting\n",
    "   - Use a real database (PostgreSQL, MongoDB)\n",
    "   - Deploy frontend to Vercel/Netlify\n",
    "   - Deploy backend to Railway/Render/AWS\n",
    "\n",
    "2. **Add More Features**\n",
    "   - Implement streaming responses\n",
    "   - Add function calling/tools\n",
    "   - Support file uploads\n",
    "   - Add conversation summarization\n",
    "\n",
    "3. **Improve UX**\n",
    "   - Add loading indicators\n",
    "   - Implement error handling\n",
    "   - Add conversation search\n",
    "   - Enable conversation export\n",
    "\n",
    "4. **Monitor and Optimize**\n",
    "   - Add logging and monitoring\n",
    "   - Implement caching\n",
    "   - Track usage and costs\n",
    "   - Optimize response times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [ChatKit Documentation](https://github.com/openai/chatkit-js)\n",
    "- [OpenAI Responses API](https://platform.openai.com/docs/guides/text-generation)\n",
    "- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n",
    "- [ChatKit Advanced Examples](https://github.com/openai/openai-chatkit-advanced-samples)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to integrate ChatKit with OpenAI's Responses API to build a modern chat interface. The key advantages of this approach are:\n",
    "\n",
    "- üöÄ **Simple Architecture** - Direct API calls, easy to understand\n",
    "- üé® **Beautiful UI** - Professional ChatKit interface\n",
    "- üîß **Full Control** - Manage your own conversation state\n",
    "- üí∞ **Cost Effective** - Only pay for tokens used\n",
    "- üîå **Flexible** - Easy to add custom features\n",
    "\n",
    "You can extend this foundation to build sophisticated chat applications with custom tools, integrations, and business logic!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
