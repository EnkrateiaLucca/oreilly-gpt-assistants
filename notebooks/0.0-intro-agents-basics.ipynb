{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Agents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is an agent?\n",
    "\n",
    "An agent is a reference to combining models that can perform some kind of reasoning, like large language models (e.g ChatGPT, Llama2, Mistral, etc...) with tools to give it access to the real world,\n",
    "so they can do things like browsing the internet, buying stuff, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so, why is there so much hype around agents right now?\n",
    "\n",
    "Because Agents are cool! Recently with the advance of LLMs, we've seen them become an amazing tool to do all sorts of things like building apps, browse the internet and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOme neat examples of these kinds of agents can be found in here:\n",
    "\n",
    "- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n",
    "- [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)\n",
    "- [BabyAGI](https://github.com/yoheinakajima/babyagi)\n",
    "\n",
    "Now, today although they seem extremely powerful, agents are still at a very early stage in terms of readiness to deploy as products, something you can atest by listening to Andrej Karpathy talk about agents in this talk here:\n",
    "\n",
    "- [Karpathy on Agents](https://www.youtube.com/watch?v=fqVLjtvWgq8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This live-training is all about! Getting you excited about this amazing new technology, understanding it from the ground up but with a focus on practical applications and fun stuff you can do with them! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an Agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent is nothing more than some entity that can _think_ and _act_, that's right, in a way you're an agent! \n",
    "\n",
    "After all you can think and act on those thoughts like in the case of coming to this live-training:\n",
    "\n",
    "- Thought: \"I want to learn about agents\"\n",
    "\n",
    "- Action: \"Go to the internet and research cool platforms where I can learn about agents\"\n",
    "\n",
    "- Thought: \"O'Reilly has some awesome courses and live-trainings\"\n",
    "\n",
    "- Action: \"Look up O'Reilly courses\"\n",
    "\n",
    "- Thought: \"Live-trainings by instructor Lucas are awesome\"\n",
    "\n",
    "- Action: \"Schedule live-training about agents with instructor Lucas Soares\" (lol)\n",
    "\n",
    "In a way this is a simplified rendition of what brought you here, obviously not necessarily in this particular order nor these particular sets of thought and action pairs. This particular way of thinking about how to structure thoughts and actions is well represented in the paper: [ReACT](https://arxiv.org/pdf/2210.03629.pdf). \n",
    "\n",
    "With regards to LLMs, how can bring this idea to fruition thinking about the LLM model as the reasoning and thinking engine?\n",
    "\n",
    "We can start simple and just call the openai API to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (2.10.5)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/greatmaster/miniconda3/envs/gpt-assistants/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if running locally\n",
    "#!pip install python-dotenv\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why did the bald teacher love explaining agents to his wonderful students?\n",
       "\n",
       "Because he knew that sometimes the best ideas come from \"shedding\" old beliefs!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            # The control over the behavior of the model\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "            # The prompt from the user\n",
    "            {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "output = get_response(\"Create a joke about a bald teacher explaining agents to wonderful students.\")\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2025-10-28-14-22-39.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok cool, so here we have three ideas of actions to perform:\n",
    "\n",
    "- Creating directories\n",
    "- Listing files\n",
    "- Removing files\n",
    "\n",
    "Let's transform them into functions that we could call just like in any type of Python-based application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(dir_name):\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "def create_file(filename):\n",
    "    with open(filename, 'w'):\n",
    "        pass\n",
    "\n",
    "def list_files():\n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's imagine that we wanted to create an agent that would perform these actions for us based on some input that we give it, how can we connect models that we know and can use today like ChatGPT, with these tools that do stuff in the real world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, how about we give a task to the model, and for that task we ask it to list the steps that it needs to perform to complete the task, and then for each of those steps we would ask the model to decide whether or not a function should be called to execute that task? \n",
    "\n",
    "In the famous paper ['Toolformer'](https://arxiv.org/pdf/2302.04761.pdf) they demonstrated that today's advanced LLMs like the gpt-series could teacha themselves how to properly call and use external tools!\n",
    "\n",
    "Isn't that awesome???\n",
    "\n",
    "So, let's see if we can hack our way into connecting the llm response with the functions that we want that llm to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets-resources/2025-10-28-14-25-05.png\" width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how can we actually put it all together so that given a task, a model can:\n",
    "\n",
    "- Plan the task\n",
    "- Execute actions to complete the task\n",
    "- Know when to call a function\n",
    "\n",
    "\n",
    "This is actually an interesting problem, let's understand why is that the case by trying to hack our way into putting all of these together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "create_directory('funny-pancakes-recipes')\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_response(prompt_question, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def create_directory(dir_name):\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "def create_file(filename):\n",
    "    with open(filename, 'w'):\n",
    "        pass\n",
    "\n",
    "def list_files():\n",
    "    files = os.listdir()\n",
    "    for file in files:\n",
    "        print(file)\n",
    "\n",
    "    \n",
    "\n",
    "task_description = \"Create a folder called 'funny-pancakes-recipes'. Inside that folder, \\\n",
    "create a file called '3-funny-pancake-recipes.md\"\n",
    "\n",
    "prompt = f\"\"\"Given this task: {task_description}, \\n\n",
    "        Consider you have access to the following functions:\n",
    "                            \n",
    "    def create_directory(dir_name):\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "    def create_file():\n",
    "        with open('test.txt', 'w'):\n",
    "            pass\n",
    "\n",
    "    def list_files():\n",
    "        files = os.listdir()\n",
    "        for file in files:\n",
    "            print(file)\n",
    "    \n",
    "    Your output should be the first function to be executed to complete the task containing the necessary arguments.\n",
    "    The OUTPUT SHOULD ONLY BE THE PYTHON FUNCTION CALL and NOTHING ELSE.\n",
    "    \"\"\"\n",
    "\n",
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "create_directory('funny-pancakes-recipes')"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Remove any ```python or ``` tags from the output string if present\n",
    "output_clean = output.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "Markdown(output_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(output_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m./funny-pancakes-recipes\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36m./pancakes-are-better-than-waffles\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d ./* | grep pancakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2025-10-28-14-32-16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can start identifying a lot of issues with this approach despite our early sucess:\n",
    "\n",
    "- Uncertainty of model's outputs can affect our ability to reliably call the functions\n",
    "- We need more structured ways to prepare the inputs of the function calls\n",
    "- We need better ways to put everything together (just feeding the entire functions like this makes it a very clunky and non-scalable framework for more complex cases)\n",
    "\n",
    "There are many more issues but starting with these, we can now look at frameworks and see how they fix these issues and with that in mind understand what is behind their implementations!\n",
    "\n",
    "I personally think this is a much better way to understand what is going on behind agents in practice rather than just use the more higher level frameworks right of the bat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's first understand how [OpenAI](https://openai.com/) the company behind ChatGPT, allows for these function call implementations in its API.\n",
    "\n",
    "OpenAI implemented a [function calling API](https://platform.openai.com/docs/guides/function-calling) which is a standard way to connect their models to outside tools like in the very simple example we did above.\n",
    "\n",
    "According to their [official documentation](https://platform.openai.com/docs/guides/function-calling#:~:text=The%20basic%20sequence,to%20the%20user.) the sequence of steps for function calling is as follows:\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call one or more functions; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example taken from their official documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how our previous model with those three simple functions: `create_directory()`, `create_file()`, and `list_files()` would be implemented using OpenAI's function calling approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "\n",
    "def create_directory(directory_name):\n",
    "    \"\"\"Function that creates a directory given a directory name.\"\"\"\n",
    "    os.mkdir(directory_name)\n",
    "    return json.dumps({\"directory_name\": directory_name})\n",
    "\n",
    "\n",
    "tool_create_directory = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"create_directory\",\n",
    "        \"description\": \"Create a directory given a directory name.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"directory_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the directory to create.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"directory_name\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = [tool_create_directory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CVf91lUDyYC4BlqEbk87d5H01yKI6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"A folder named 'pancakes-are-better-than-waffles' has been created successfully.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761662363, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=21, prompt_tokens=74, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def run_terminal_task():\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"Create a folder called 'pancakes-are-better-than-waffles'.\"}]\n",
    "    tools = [tool_create_directory]  \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    \n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"create_directory\": create_directory,\n",
    "        }\n",
    "        messages.append(response_message)\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                directory_name=function_args.get(\"directory_name\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return second_response\n",
    "\n",
    "output = run_terminal_task()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A folder named 'pancakes-are-better-than-waffles' has been created successfully.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mpancakes-are-better-than-waffles/\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d */ | grep waffles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We implemented openai function calling for creating directories! We could evolve this approach but let's stop for now.\n",
    "\n",
    "See more info on these examples from OpenAI's [official cookbook](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folder path was created at: lucas-test-agent'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_dir(folder_path):\n",
    "    \"\"\"\n",
    "    Creates a directory given a folder path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    \n",
    "    return f\"Folder path was created at: {folder_path}\"\n",
    "\n",
    "\n",
    "create_dir(\"lucas-test-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mlucas-test-agent/\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -d */ | grep lucas-test-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A file was created at: ./lucas-test-agent/file-text.txt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_file(file_path, contents=\"\"):\n",
    "    \"\"\"\n",
    "    Creates a file with content.\n",
    "    If no content is provided it will create an empty file.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(contents)\n",
    "    \n",
    "    return f\"A file was created at: {file_path}\"\n",
    "\n",
    "create_file(\"./lucas-test-agent/file-text.txt\", \"This is a test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads from file given its path.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        contents = f.read()\n",
    "    \n",
    "    return contents\n",
    "\n",
    "read_file(\"./lucas-test-agent/file-text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools in OpenAI format\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_dir\",\n",
    "            \"description\": \"Creates a directory given a folder path.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"folder_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The path of the folder to create\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"folder_path\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_file\",\n",
    "            \"description\": \"Creates a file with content. If no content is provided it will create an empty file.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"file_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The path where the file should be created\"\n",
    "                    },\n",
    "                    \"contents\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The content to write to the file (optional)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"file_path\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_file\",\n",
    "            \"description\": \"Reads from file given its path.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"file_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The path of the file to read\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"file_path\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create mapping of function names to actual functions\n",
    "tool_mapping = {\n",
    "    \"create_dir\": create_dir,\n",
    "    \"create_file\": create_file,\n",
    "    \"read_file\": read_file\n",
    "}\n",
    "\n",
    "def llm_call(query, observations=[], actions_taken=[]):\n",
    "    \"\"\"\n",
    "    Calls the llm using OpenAI's chat completions API with function calling.\n",
    "    It can return a tool call with arguments for calling different tools,\n",
    "    or an output to the user.\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    Imagine you are a simple assistant tasked with managing a file system. You have access to three tools:\n",
    "    \n",
    "    1. create_dir: Creates a new directory.\n",
    "    2. create_file: Creates a new file and optionally writes content to it.\n",
    "    3. read_file: Reads the contents of an existing file.\n",
    "\n",
    "    Based on the user input and your observations, choose an action to execute. Your action must follow these guidelines:\n",
    "    \n",
    "    * Action Guidelines *\n",
    "    1) Only one action is allowed per iteration.\n",
    "    2) Be concise and specific about what to create, write, or read.\n",
    "    3) Provide clear reasoning for your action.\n",
    "    4) Always consider the current context before taking action.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "User Query: {query}\n",
    "Observations: {observations}\n",
    "Actions Taken So Far: {actions_taken}\n",
    "\"\"\"}\n",
    "    ]\n",
    "\n",
    "    # Call OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    \n",
    "    # Check if the model wants to call a function\n",
    "    if response_message.tool_calls:\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            # Check if function_name exists in tool_mapping\n",
    "            if function_name not in tool_mapping:\n",
    "                print(f\"Error: Unknown function name '{function_name}'\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Attempt to call the function with the provided arguments\n",
    "                tool_output = tool_mapping[function_name](**function_args)\n",
    "                actions_taken.append(function_name)\n",
    "                observations.append(tool_output)\n",
    "            except TypeError as e:\n",
    "                # Handle errors if the number of arguments does not match\n",
    "                print(f\"Error: Invalid arguments for function '{function_name}': {e}\")\n",
    "    \n",
    "    return response_message, actions_taken, observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2025-10-28-14-49-49.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_NrwUV8lID7mZrQunXSjyGjDR', function=Function(arguments='{\"folder_path\":\"openai-tests-tool-calling\"}', name='create_dir'), type='function')])\n",
      "Actions: ['create_dir']\n",
      "Observations: ['Folder path was created at: openai-tests-tool-calling']\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Create a directory\n",
    "output, actions, observations = llm_call(\"Create a folder named: openai-tests-tool-calling\")\n",
    "print(\"Output:\", output)\n",
    "print(\"Actions:\", actions)\n",
    "print(\"Observations:\", observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_2rrR7q1b8DosjOVsJcCyj8jq', function=Function(arguments='{\"file_path\":\"./openai-tests-tool-calling/test1.txt\",\"contents\":\"Hello! This is a test using OpenAI\\'s function calling API!\"}', name='create_file'), type='function')])\n",
      "Actions: ['create_dir', 'create_file']\n",
      "Observations: ['Folder path was created at: openai-tests-tool-calling', 'A file was created at: ./openai-tests-tool-calling/test1.txt']\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Create a file with content\n",
    "output, actions, observations = llm_call(\n",
    "    \"Create a file at: ./openai-tests-tool-calling/test1.txt with the contents: Hello! This is a test using OpenAI's function calling API!\",\n",
    "    observations=[\"Folder path was created at: openai-tests-tool-calling\"],\n",
    "    actions_taken=[\"create_dir\"]\n",
    ")\n",
    "print(\"Output:\", output)\n",
    "print(\"Actions:\", actions)\n",
    "print(\"Observations:\", observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_nNs2UtkXuY9kjmV1uKkHE6NI', function=Function(arguments='{\"file_path\":\"./openai-tests-tool-calling/test1.txt\"}', name='read_file'), type='function')])\n",
      "Actions: ['create_dir', 'create_file', 'read_file']\n",
      "Observations: ['Folder path was created at: openai-tests-tool-calling', 'A file was created at: ./openai-tests-tool-calling/test1.txt', \"Hello! This is a test using OpenAI's function calling API!\"]\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Read file contents\n",
    "output, actions, observations = llm_call(\n",
    "    \"Read the file contents from ./openai-tests-tool-calling/test1.txt\",\n",
    "    observations=[\n",
    "        \"Folder path was created at: openai-tests-tool-calling\",\n",
    "        \"A file was created at: ./openai-tests-tool-calling/test1.txt\"\n",
    "    ],\n",
    "    actions_taken=[\"create_dir\", \"create_file\"]\n",
    ")\n",
    "print(\"Output:\", output)\n",
    "print(\"Actions:\", actions)\n",
    "print(\"Observations:\", observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "  Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_nxVo8ehW5EVUIo0PicG7JhcR', function=Function(arguments='{\"folder_path\": \"testing-openai-agents\"}', name='create_dir'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_cYakPce7mem6VaiUH0C1lkB8', function=Function(arguments='{\"file_path\": \"testing-openai-agents/test-file.txt\", \"contents\": \"Hello from OpenAI API!\"}', name='create_file'), type='function')]\n",
      "  Content: No content\n",
      "  Actions taken: ['create_dir', 'create_file']\n",
      "  Observations: ['Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt']\n",
      "\n",
      "Iteration 2:\n",
      "  Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_8flQU2Dpt92PhBxsXal4Pz4C', function=Function(arguments='{\"folder_path\": \"testing-openai-agents\"}', name='create_dir'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_SEbPtL4rZezBpBEcA8uoVXeE', function=Function(arguments='{\"file_path\": \"testing-openai-agents/test-file.txt\", \"contents\": \"Hello from OpenAI API!\"}', name='create_file'), type='function')]\n",
      "  Content: No content\n",
      "  Actions taken: ['create_dir', 'create_file', 'create_dir', 'create_file']\n",
      "  Observations: ['Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt']\n",
      "\n",
      "Iteration 3:\n",
      "  Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_eJLlvOJVSvJ86wUo3D6YuM2O', function=Function(arguments='{\"folder_path\": \"testing-openai-agents\"}', name='create_dir'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_GIyZyaT1LCzIfsyecZVJ9RKB', function=Function(arguments='{\"file_path\": \"testing-openai-agents/test-file.txt\", \"contents\": \"Hello from OpenAI API!\"}', name='create_file'), type='function')]\n",
      "  Content: No content\n",
      "  Actions taken: ['create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file']\n",
      "  Observations: ['Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt']\n",
      "\n",
      "Iteration 4:\n",
      "  Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_MU4OO0RazjdlhDM4KlO0phv8', function=Function(arguments='{\"folder_path\": \"testing-openai-agents\"}', name='create_dir'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_9VLMeCpBAypjSaIwRyaUWkNN', function=Function(arguments='{\"file_path\": \"testing-openai-agents/test-file.txt\", \"contents\": \"Hello from OpenAI API!\"}', name='create_file'), type='function')]\n",
      "  Content: No content\n",
      "  Actions taken: ['create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file']\n",
      "  Observations: ['Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt']\n",
      "\n",
      "Iteration 5:\n",
      "  Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_PKuLgRJdErmLjj2AhFI8d0Ny', function=Function(arguments='{\"folder_path\": \"testing-openai-agents\"}', name='create_dir'), type='function'), ChatCompletionMessageFunctionToolCall(id='call_727MejhxQE0194DYIHfL9NU6', function=Function(arguments='{\"file_path\": \"testing-openai-agents/test-file.txt\", \"contents\": \"Hello from OpenAI API!\"}', name='create_file'), type='function')]\n",
      "  Content: No content\n",
      "  Actions taken: ['create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file', 'create_dir', 'create_file']\n",
      "  Observations: ['Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt', 'Folder path was created at: testing-openai-agents', 'A file was created at: testing-openai-agents/test-file.txt']\n",
      "\n",
      "Breaking after 5 iterations\n",
      "\n",
      "Final result: Task completed\n"
     ]
    }
   ],
   "source": [
    "def agent_loop(query, max_iterations=5):\n",
    "    \"\"\"\n",
    "    Agent loop that continues calling llm_call until the task is complete\n",
    "    or max iterations is reached.\n",
    "    \"\"\"\n",
    "    iter_count = 0\n",
    "    obs = []\n",
    "    acts_taken = []\n",
    "    \n",
    "    while True:\n",
    "        output, acts_taken, obs = llm_call(query, obs, acts_taken)\n",
    "        print(f\"Iteration {iter_count + 1}:\")\n",
    "        print(f\"  Tool calls: {output.tool_calls if output.tool_calls else 'None'}\")\n",
    "        print(f\"  Content: {output.content if output.content else 'No content'}\")\n",
    "        print(f\"  Actions taken: {acts_taken}\")\n",
    "        print(f\"  Observations: {obs}\")\n",
    "        print()\n",
    "        \n",
    "        iter_count += 1\n",
    "        \n",
    "        # Break if we hit max iterations\n",
    "        if iter_count >= max_iterations:\n",
    "            print(f\"Breaking after {iter_count} iterations\")\n",
    "            break\n",
    "        \n",
    "        # Break if the model returns content without tool calls (task complete)\n",
    "        if output.content and not output.tool_calls:\n",
    "            break\n",
    "    \n",
    "    return output.content if output.content else \"Task completed\"\n",
    "\n",
    "\n",
    "# Test the agent loop\n",
    "result = agent_loop(\"Create a folder in current directory named 'testing-openai-agents' and inside that folder create a file named test-file.txt with content 'Hello from OpenAI API!'\")\n",
    "print(\"\\nFinal result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [HuggingGPT](https://github.com/microsoft/JARVIS)\n",
    "- [Gen Agents](https://arxiv.org/pdf/2304.03442.pdf)\n",
    "- [WebGPT](https://www.semanticscholar.org/paper/WebGPT%3A-Browser-assisted-question-answering-with-Nakano-Hilton/2f3efe44083af91cef562c1a3451eee2f8601d22)\n",
    "- [LangChain](https://python.langchain.com/docs/get_started/introduction)\n",
    "- [OpenAI](https://openai.com/)\n",
    "- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n",
    "- [GPT-Engineer](https://github.com/gpt-engineer-org/gpt-engineer)\n",
    "- [BabyAGI](https://github.com/yoheinakajima/babyagi)\n",
    "- [Karpathy on Agents](https://www.youtube.com/watch?v=fqVLjtvWgq8)\n",
    "- [ReACT Paper](https://arxiv.org/abs/2210.03629)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-agents",
   "language": "python",
   "name": "oreilly-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
